{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "    1. Feature Engineering: class video, Prince's Post (copy exactly what he does) and other Kaggle posts.\n",
    "    4. Try extremly randomized tree models\n",
    "    6. Unbalanced dataset (in later ML classes)\n",
    "    7. Use prun to invesitgate which line takes the most of time within one function.\n",
    "    8. lesson4 video : 1:09 --> Feature Importance\n",
    "    9. ----- TODO ----: I did not tune current model. Do that and do other steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model metric from Kaggle\n",
    "def gini(actuals, preds, cmpcol = 0, sortcol = 1):\n",
    "     assert( len(actuals) == len(preds) )\n",
    "     all = np.asarray(np.c_[ actuals, preds, np.arange(len(actuals)) ], dtype=np.float)\n",
    "     all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "     totalLosses = all[:,0].sum()\n",
    "     giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "     giniSum -= (len(actuals) + 1) / 2.\n",
    "     return giniSum / len(actuals)\n",
    " \n",
    "def gini_normalized(actuals, preds):\n",
    "    return abs(gini(actuals, preds) / gini(actuals, actuals))\n",
    "\n",
    "gini_score = make_scorer(gini_normalized, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "def print_score(m, X_train, X_test, y_train, y_test):\n",
    "    preds_train = m.predict_proba(X_train)\n",
    "    preds_test = m.predict_proba(X_test)\n",
    "    preds1 = [row[1] for row in preds_train]\n",
    "    preds2 = [row[1] for row in preds_test]\n",
    "    res = [gini_normalized(y_train, preds1), gini_normalized(y_test, preds2),\n",
    "                m.score(X_train, y_train), m.score(X_test, y_test)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    # print(res)\n",
    "    return res\n",
    "\n",
    "# Write prediction result to local file\n",
    "def writeTOfile(nums1, nums2, fname):\n",
    "    # nums is id list, and nums2 is probabilities of preidiction\n",
    "    if len(nums1)!=len(nums2): return\n",
    "    s = \"id,target\\n\"\n",
    "    for i in range(0, len(nums1)):\n",
    "        s += str(nums1[i]) + \",\" + str(nums2[i]) + \"\\n\"\n",
    "    f = open(f'{PATH}{fname}', 'w')\n",
    "    f.write(s)\n",
    "    \n",
    "def split_vals(df, n): return df[:n].copy(), df[n:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = \"data/\"\n",
    "df_raw = pd.read_csv(f'{PATH}train.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df is used for non-feature engineering\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df1 is used for feature engineering\n",
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 59)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "\n",
       "[2 rows x 59 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA & Feature Engineering\n",
    "- Features that belong to similar groupings are tagged as such in the feaure names (ind, reg, car, calc)\n",
    "- bin -> Binary feature; cat -> categorical features; Others are either continuous or ordinal.\n",
    "- -1 refers to missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naEiSuhkakqRuhoYkqdv/BxkPpUl8bN/EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2707ab31d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of claims filed : 3.64475178592 %\n"
     ]
    }
   ],
   "source": [
    "# distribution of response varaible 'target'\n",
    "plt.hist(df1['target'])\n",
    "plt.show()\n",
    "print('Percentage of claims filed :' , str(np.sum(df1['target'])/df1.shape[0]*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us handle missing values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values (denoted by -1)\n",
      "ps_car_03_cat    69.089837\n",
      "ps_car_05_cat    44.782531\n",
      "ps_reg_03        18.106490\n",
      "ps_car_14         7.160474\n",
      "ps_car_07_cat     1.930237\n",
      "ps_ind_05_cat     0.975955\n",
      "ps_car_09_cat     0.095596\n",
      "ps_ind_02_cat     0.036290\n",
      "ps_car_01_cat     0.017977\n",
      "ps_ind_04_cat     0.013945\n",
      "ps_car_11         0.000840\n",
      "ps_car_02_cat     0.000840\n",
      "ps_car_12         0.000168\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Perentage of missing values in each column.\n",
    "missing = np.sum(df1 == -1)/df1.shape[0]*100\n",
    "print(\"Percentage of missing values (denoted by -1)\")\n",
    "print(missing[missing > 0].sort_values(ascending = False))\n",
    "missing_vars = missing[missing > 0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a column varname_NA for each row with NAs\n",
    "2. Replace -1 with mean for continuous variables\n",
    "3. Create a new column counting number of NAs in current row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for var_name in missing_vars:\n",
    "    if \"ps_car_12\" in var_name: continue\n",
    "    is_null = (df1[var_name] == -1)\n",
    "    df1[var_name + \"_NA\"] = is_null.astype(int)\n",
    "    if 'cat' not in var_name:\n",
    "        is_not_null = [not b for b in is_null]\n",
    "        df1[var_name][is_null] = sum(df1[var_name][is_not_null]) / sum(is_not_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['num_NAs'] = (df1 == -1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values (denoted by -1)\n",
      "ps_car_03_cat    69.089837\n",
      "ps_car_05_cat    44.782531\n",
      "ps_car_07_cat     1.930237\n",
      "ps_ind_05_cat     0.975955\n",
      "ps_car_09_cat     0.095596\n",
      "ps_ind_02_cat     0.036290\n",
      "ps_car_01_cat     0.017977\n",
      "ps_ind_04_cat     0.013945\n",
      "ps_car_02_cat     0.000840\n",
      "ps_car_12         0.000168\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Now all columns (except categorical ones) have no missing values. Keep ps_car_12 \n",
    "## for being compatible with test dataset\n",
    "missing = np.sum(df1 == -1)/df1.shape[0]*100\n",
    "print(\"Percentage of missing values (denoted by -1)\")\n",
    "print(missing[missing > 0].sort_values(ascending = False))\n",
    "missing_vars = missing[missing > 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'target', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03',\n",
       "       'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin',\n",
       "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
       "       'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15',\n",
       "       'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01',\n",
       "       'ps_reg_02', 'ps_reg_03', 'ps_car_01_cat', 'ps_car_02_cat',\n",
       "       'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat',\n",
       "       'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat',\n",
       "       'ps_car_11_cat', 'ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14',\n",
       "       'ps_car_15', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04',\n",
       "       'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09',\n",
       "       'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
       "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
       "       'ps_calc_19_bin', 'ps_calc_20_bin', 'ps_ind_02_cat_NA',\n",
       "       'ps_ind_04_cat_NA', 'ps_ind_05_cat_NA', 'ps_reg_03_NA',\n",
       "       'ps_car_01_cat_NA', 'ps_car_02_cat_NA', 'ps_car_03_cat_NA',\n",
       "       'ps_car_05_cat_NA', 'ps_car_07_cat_NA', 'ps_car_09_cat_NA',\n",
       "       'ps_car_11_NA', 'ps_car_14_NA', 'num_NAs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on explanation from Kaggle, 'bin' refers to binary variable, 'cat' refers to categorical variable, and others are continuous and ordinal ('cat' should mean Nominal variable here). We should take care of 'cat' variable, and leave others as they are. This is because categorical variables in this example don't have order embedded, there is no meaning to treat them as numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comment for experiment. May use it later\n",
    "for col in df1:\n",
    "    if 'cat' in col and 'NA' not in col:\n",
    "        df1 = df1.join(pd.get_dummies(df1[col], prefix = col))\n",
    "        df1 = df1.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'target', 'ps_ind_01', 'ps_ind_03', 'ps_ind_06_bin',\n",
       "       'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin',\n",
       "       'ps_ind_11_bin',\n",
       "       ...\n",
       "       'ps_car_11_cat_95', 'ps_car_11_cat_96', 'ps_car_11_cat_97',\n",
       "       'ps_car_11_cat_98', 'ps_car_11_cat_99', 'ps_car_11_cat_100',\n",
       "       'ps_car_11_cat_101', 'ps_car_11_cat_102', 'ps_car_11_cat_103',\n",
       "       'ps_car_11_cat_104'],\n",
       "      dtype='object', length=242)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add round(ps_car_13^2 * 48400, 2)\n",
    "# df1[\"ps_car_13\"]^2*48400\n",
    "# df1[\"ps_car_13_new\"] = [round(math.pow(item, 2)*48400, 2) for item in df1[\"ps_car_13\"]]\n",
    "df1[\"ps_car_13_new\"] = [round(math.pow(item, 2)*90000, 2) for item in df1[\"ps_car_13\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "### Training VS Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert 'target' to categorical variable\n",
    "df['target'] = df['target'].astype('category')\n",
    "df1['target'] = df1['target'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = df1.drop('target', axis = 1)\n",
    "y1 = df1.iloc[:,1]\n",
    "# train_test split on the original dataset\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.30, random_state = 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('target', axis = 1)\n",
    "y = df.iloc[:,1]\n",
    "# train_test split on the original dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((416648, 242), (416648,), (178564, 242), (178564,))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train.shape, y1_train.shape, X1_test.shape, y1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((416648, 58), (416648,), (178564, 58), (178564,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us check if feature engineering help for classification ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform according transformation on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in test dataset\n",
    "test_df = pd.read_csv(f'{PATH}test.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values (denoted by -1)\n",
      "ps_car_03_cat    69.097216\n",
      "ps_car_05_cat    44.842274\n",
      "ps_reg_03        18.109442\n",
      "ps_car_14         7.146489\n",
      "ps_car_07_cat     1.941161\n",
      "ps_ind_05_cat     0.975565\n",
      "ps_car_09_cat     0.098229\n",
      "ps_ind_02_cat     0.034386\n",
      "ps_car_01_cat     0.017921\n",
      "ps_ind_04_cat     0.016241\n",
      "ps_car_02_cat     0.000560\n",
      "ps_car_11         0.000112\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Perentage of missing values in each column.\n",
    "missing = np.sum(test_df == -1)/test_df.shape[0]*100\n",
    "print(\"Percentage of missing values (denoted by -1)\")\n",
    "print(missing[missing > 0].sort_values(ascending = False))\n",
    "missing_vars = missing[missing > 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for var_name in missing_vars:\n",
    "    is_null = (test_df[var_name] == -1)\n",
    "    test_df[var_name + \"_NA\"] = is_null.astype(int)\n",
    "    if 'cat' not in var_name:\n",
    "        is_not_null = [not b for b in is_null]\n",
    "        test_df[var_name][is_null] = sum(test_df[var_name][is_not_null]) / sum(is_not_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['num_NAs'] = (test_df == -1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values (denoted by -1)\n",
      "ps_car_03_cat    69.097216\n",
      "ps_car_05_cat    44.842274\n",
      "ps_car_07_cat     1.941161\n",
      "ps_ind_05_cat     0.975565\n",
      "ps_car_09_cat     0.098229\n",
      "ps_ind_02_cat     0.034386\n",
      "ps_car_01_cat     0.017921\n",
      "ps_ind_04_cat     0.016241\n",
      "ps_car_02_cat     0.000560\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Perentage of missing values in each column.\n",
    "missing = np.sum(test_df == -1)/test_df.shape[0]*100\n",
    "print(\"Percentage of missing values (denoted by -1)\")\n",
    "print(missing[missing > 0].sort_values(ascending = False))\n",
    "missing_vars = missing[missing > 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in test_df:\n",
    "    if 'cat' in col and 'NA' not in col:\n",
    "        test_df = test_df.join(pd.get_dummies(test_df[col], prefix = col))\n",
    "        test_df = test_df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df[\"ps_car_13_new\"] = \\\n",
    "[round(math.pow(item, 2)*90000, 2) for item in test_df[\"ps_car_13\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters without downsampling for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = df.columns.drop(['id', 'target'], 1); \n",
    "rf = RandomForestClassifier(random_state=20, n_jobs = -1)\n",
    "# Grid of parameters to Tune\n",
    "param_grid = {\"n_estimators\": np.arange(1, 500, 25, dtype = int),\n",
    "              \"max_depth\": np.arange(1, 20, 2),\n",
    "              #\"min_samples_split\": np.arange(1,150,1),\n",
    "              \"min_samples_leaf\": [1,5,10,20,30,50,70,100,200,300]\n",
    "              #\"max_leaf_nodes\": np.arange(2,60,6),\n",
    "              #\"min_weight_fraction_leaf\": np.arange(0.1,0.4, 0.1)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19]),\n",
       " 'min_samples_leaf': [1, 5, 10, 20, 30, 50, 70, 100, 200, 300],\n",
       " 'n_estimators': array([  1,  26,  51,  76, 101, 126, 151, 176, 201, 226, 251, 276, 301, 326, 351, 376, 401, 426, 451, 476])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.266155569614\n",
      "{'n_estimators': 226, 'min_samples_leaf': 70, 'max_depth': 19}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=19, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=70, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=226, n_jobs=-1,\n",
      "            oob_score=False, random_state=20, verbose=0, warm_start=False)\n",
      "CPU times: user 1h 7min 52s, sys: 15.2 s, total: 1h 8min 8s\n",
      "Wall time: 34min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "random_cv = RandomizedSearchCV(rf, param_distributions = param_grid, cv = 3, scoring = gini_score)\n",
    "random_cv.fit(X1_train, y1_train)\n",
    "print(random_cv.best_score_)\n",
    "print(random_cv.best_params_)\n",
    "print(random_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 6s, sys: 248 ms, total: 4min 6s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = RandomForestClassifier(n_jobs=-1, max_depth=19, n_estimators=226, min_samples_leaf=70)\n",
    "m.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.63456250740426523,\n",
       " 0.26415977208101532,\n",
       " 0.96345596282713464,\n",
       " 0.9637776931520351]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(m, X1_train, X1_test, y1_train, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 47s, sys: 1.37 s, total: 6min 49s\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_jobs=-1, max_depth=19, n_estimators=226, min_samples_leaf=70)\n",
    "# Fit the whole dataset\n",
    "clf.fit(df1.drop(['target', 'id'], axis=1), df1.target)\n",
    "# Load in test dataset\n",
    "# test_df = pd.read_csv(f'{PATH}test.csv', low_memory = False)\n",
    "# Predict probabilites for test data\n",
    "result = clf.predict_proba(test_df.drop('id', axis=1))\n",
    "predictions = [row[1] for row in result]\n",
    "id_list = test_df.id.tolist()\n",
    "writeTOfile(id_list, predictions, \"submission5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters using downsampling\n",
    "\n",
    "** Note: CV is super expensive - use it before planning **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Todo: Why downsampling? And How? **\n",
    "Downsampling because data is unbalanced.\n",
    "- 1/20 (Trues are 2500/ 50,000)\n",
    "- 1/15 (Trues are 3333/ 50,000)\n",
    "- 1/10 (Trues are 5000/ 50,000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pick n_estimators = 357, max_depth = 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chengcheng/anaconda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.222150406987\n",
      "{'n_estimators': 425, 'max_depth': 5}\n",
      "0.264078349449\n",
      "{'n_estimators': 375, 'max_depth': 9}\n",
      "0.255701837486\n",
      "{'n_estimators': 475, 'max_depth': 11}\n",
      "0.261694942434\n",
      "{'n_estimators': 375, 'max_depth': 6}\n",
      "0.241504690974\n",
      "{'n_estimators': 225, 'max_depth': 7}\n",
      "0.241998392\n",
      "{'n_estimators': 275, 'max_depth': 8}\n",
      "0.262164800521\n",
      "{'n_estimators': 325, 'max_depth': 7}\n",
      "0.237835631964\n",
      "{'n_estimators': 275, 'max_depth': 9}\n",
      "0.247183548639\n",
      "{'n_estimators': 425, 'max_depth': 8}\n",
      "CPU times: user 1h 27min 22s, sys: 1min 46s, total: 1h 29min 9s\n",
      "Wall time: 31min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(3):\n",
    "    for j in [2500, 3333, 5000]:\n",
    "        index0 = df.index[df['target'] == 0]\n",
    "        index1 = df.index[df['target'] == 1]\n",
    "        index = random.sample(list(index0), 50000 - j) + random.sample(list(index1), j)\n",
    "        df_tmp = df.ix[index]\n",
    "\n",
    "        # splitting y and x\n",
    "        X_tmp = df_tmp[features]\n",
    "        y_tmp = df_tmp.iloc[:,1]\n",
    "              \n",
    "        random_cv = RandomizedSearchCV(rf, param_distributions = param_grid, cv = 3, scoring = gini_score)\n",
    "        random_cv.fit(X_tmp, y_tmp)\n",
    "        print(random_cv.best_score_)\n",
    "        print(random_cv.best_params_)\n",
    "        #print(random_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try tunned parameters on training / testing of whole dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 120 ms, total: 2min 2s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m1 = RandomForestClassifier(n_jobs=-1, max_depth=13, n_estimators=176)\n",
    "m1.fit(X_train, y_train)\n",
    "# print_score(m1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75318430847770046,\n",
       " 0.25407439316204522,\n",
       " 0.96352316583782949,\n",
       " 0.96375529222015632]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(m1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 64 ms, total: 1min 6s\n",
      "Wall time: 33.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RandomForestClassifier(n_jobs=-1, max_depth=7, n_estimators=200)\n",
    "%time m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32336971238523571,\n",
       " 0.25379381664267314,\n",
       " 0.96360958426554144,\n",
       " 0.96354243232458991]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(m, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 68 ms, total: 1min 23s\n",
      "Wall time: 42.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=9, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = RandomForestClassifier(n_jobs=-1, max_depth=9, n_estimators=200)\n",
    "%time m2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42159334455920722,\n",
       " 0.25651369797865187,\n",
       " 0.96362358488716904,\n",
       " 0.96353403196337439]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(m2, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on the whole dataset, and write predictions to local file ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 29s, sys: 896 ms, total: 3min 30s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_jobs=-1, max_depth=13, n_estimators=176)\n",
    "# Fit the whole dataset\n",
    "clf.fit(df.drop(['target', 'id'], axis=1), df.target)\n",
    "# Load in test dataset\n",
    "test_df = pd.read_csv(f'{PATH}test.csv', low_memory = False)\n",
    "# Predict probabilites for test data\n",
    "result = clf.predict_proba(test_df.drop('id', axis=1))\n",
    "predictions = [row[1] for row in result]\n",
    "id_list = test_df.id.tolist()\n",
    "writeTOfile(id_list, predictions, \"submission2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??set_rf_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_rf_samples(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45684294230428935, 0.26242798228386199, 0.96347095253995951, 0.96408860663793761]\n",
      "CPU times: user 1min 48s, sys: 8.06 s, total: 1min 56s\n",
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=357, max_depth=9, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print_score(m, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Decreasing n_esitmators to 100 doesn't seem to affect gini too much **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45683329769547293, 0.26242656338930015, 0.96347095253995951, 0.96408860663793761]\n",
      "CPU times: user 58.3 s, sys: 3.98 s, total: 1min 2s\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=9, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print_score(m, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Manually tune min_samples **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4568334140704659, 0.26243158252494841, 0.96347095253995951, 0.96408860663793761]\n",
      "CPU times: user 1min 9s, sys: 5.36 s, total: 1min 14s\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=9, min_samples_leaf=3, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print_score(m, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** Manually tune max_features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45683441639701722, 0.26243392696280193, 0.96347095253995951, 0.96408860663793761]\n",
      "CPU times: user 1min 46s, sys: 5.01 s, total: 1min 51s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=9, min_samples_leaf=3,max_features=0.5, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print_score(m, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Seems like both min_samples_leaf and max_features work, let us tune them using grid search **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.1 1\n",
      "1 0.1 2\n",
      "1 0.1 3\n",
      "1 0.1 4\n",
      "1 0.1 5\n",
      "1 0.1 6\n",
      "1 0.1 7\n",
      "1 0.1 8\n",
      "1 0.1 9\n",
      "1 0.1 10\n",
      "1 0.1 20\n",
      "1 0.1 30\n",
      "1 0.1 40\n",
      "1 0.1 50\n",
      "1 0.1 70\n",
      "1 0.1 90\n",
      "1 0.2 1\n",
      "1 0.2 2\n",
      "1 0.2 3\n",
      "1 0.2 4\n",
      "1 0.2 5\n",
      "1 0.2 6\n",
      "1 0.2 7\n",
      "1 0.2 8\n",
      "1 0.2 9\n",
      "1 0.2 10\n",
      "1 0.2 20\n",
      "1 0.2 30\n",
      "1 0.2 40\n",
      "1 0.2 50\n",
      "1 0.2 70\n",
      "1 0.2 90\n",
      "1 0.3 1\n",
      "1 0.3 2\n",
      "1 0.3 3\n",
      "1 0.3 4\n",
      "1 0.3 5\n",
      "1 0.3 6\n",
      "1 0.3 7\n",
      "1 0.3 8\n",
      "1 0.3 9\n",
      "1 0.3 10\n",
      "1 0.3 20\n",
      "1 0.3 30\n",
      "1 0.3 40\n",
      "1 0.3 50\n",
      "1 0.3 70\n",
      "1 0.3 90\n",
      "1 0.4 1\n",
      "1 0.4 2\n",
      "1 0.4 3\n",
      "1 0.4 4\n",
      "1 0.4 5\n",
      "1 0.4 6\n",
      "1 0.4 7\n",
      "1 0.4 8\n",
      "1 0.4 9\n",
      "1 0.4 10\n",
      "1 0.4 20\n",
      "1 0.4 30\n",
      "1 0.4 40\n",
      "1 0.4 50\n",
      "1 0.4 70\n",
      "1 0.4 90\n",
      "1 0.5 1\n",
      "1 0.5 2\n",
      "1 0.5 3\n",
      "1 0.5 4\n",
      "1 0.5 5\n",
      "1 0.5 6\n",
      "1 0.5 7\n",
      "1 0.5 8\n",
      "1 0.5 9\n",
      "1 0.5 10\n",
      "1 0.5 20\n",
      "1 0.5 30\n",
      "1 0.5 40\n",
      "1 0.5 50\n",
      "1 0.5 70\n",
      "1 0.5 90\n",
      "1 0.6 1\n",
      "1 0.6 2\n",
      "1 0.6 3\n",
      "1 0.6 4\n",
      "1 0.6 5\n",
      "1 0.6 6\n",
      "1 0.6 7\n",
      "1 0.6 8\n",
      "1 0.6 9\n",
      "1 0.6 10\n",
      "1 0.6 20\n",
      "1 0.6 30\n",
      "1 0.6 40\n",
      "1 0.6 50\n",
      "1 0.6 70\n",
      "1 0.6 90\n",
      "1 0.7 1\n",
      "1 0.7 2\n",
      "1 0.7 3\n",
      "1 0.7 4\n",
      "1 0.7 5\n",
      "1 0.7 6\n",
      "1 0.7 7\n",
      "1 0.7 8\n",
      "1 0.7 9\n",
      "1 0.7 10\n",
      "1 0.7 20\n",
      "1 0.7 30\n",
      "1 0.7 40\n",
      "1 0.7 50\n",
      "1 0.7 70\n",
      "1 0.7 90\n",
      "1 0.8 1\n",
      "1 0.8 2\n",
      "1 0.8 3\n",
      "1 0.8 4\n",
      "1 0.8 5\n",
      "1 0.8 6\n",
      "1 0.8 7\n",
      "1 0.8 8\n",
      "1 0.8 9\n",
      "1 0.8 10\n",
      "1 0.8 20\n",
      "1 0.8 30\n",
      "1 0.8 40\n",
      "1 0.8 50\n",
      "1 0.8 70\n",
      "1 0.8 90\n",
      "3 0.1 1\n",
      "3 0.1 2\n",
      "3 0.1 3\n",
      "3 0.1 4\n",
      "3 0.1 5\n",
      "3 0.1 6\n",
      "3 0.1 7\n",
      "3 0.1 8\n",
      "3 0.1 9\n",
      "3 0.1 10\n",
      "3 0.1 20\n",
      "3 0.1 30\n",
      "3 0.1 40\n",
      "3 0.1 50\n",
      "3 0.1 70\n",
      "3 0.1 90\n",
      "3 0.2 1\n",
      "3 0.2 2\n",
      "3 0.2 3\n",
      "3 0.2 4\n",
      "3 0.2 5\n",
      "3 0.2 6\n",
      "3 0.2 7\n",
      "3 0.2 8\n",
      "3 0.2 9\n",
      "3 0.2 10\n",
      "3 0.2 20\n",
      "3 0.2 30\n",
      "3 0.2 40\n",
      "3 0.2 50\n",
      "3 0.2 70\n",
      "3 0.2 90\n",
      "3 0.3 1\n",
      "3 0.3 2\n",
      "3 0.3 3\n",
      "3 0.3 4\n",
      "3 0.3 5\n",
      "3 0.3 6\n",
      "3 0.3 7\n",
      "3 0.3 8\n",
      "3 0.3 9\n",
      "3 0.3 10\n",
      "3 0.3 20\n",
      "3 0.3 30\n",
      "3 0.3 40\n",
      "3 0.3 50\n",
      "3 0.3 70\n",
      "3 0.3 90\n",
      "3 0.4 1\n",
      "3 0.4 2\n",
      "3 0.4 3\n",
      "3 0.4 4\n",
      "3 0.4 5\n",
      "3 0.4 6\n",
      "3 0.4 7\n",
      "3 0.4 8\n",
      "3 0.4 9\n",
      "3 0.4 10\n",
      "3 0.4 20\n",
      "3 0.4 30\n",
      "3 0.4 40\n",
      "3 0.4 50\n",
      "3 0.4 70\n",
      "3 0.4 90\n",
      "3 0.5 1\n",
      "3 0.5 2\n",
      "3 0.5 3\n",
      "3 0.5 4\n",
      "3 0.5 5\n",
      "3 0.5 6\n",
      "3 0.5 7\n",
      "3 0.5 8\n",
      "3 0.5 9\n",
      "3 0.5 10\n",
      "3 0.5 20\n",
      "3 0.5 30\n",
      "3 0.5 40\n",
      "3 0.5 50\n",
      "3 0.5 70\n",
      "3 0.5 90\n",
      "3 0.6 1\n",
      "3 0.6 2\n",
      "3 0.6 3\n",
      "3 0.6 4\n",
      "3 0.6 5\n",
      "3 0.6 6\n",
      "3 0.6 7\n",
      "3 0.6 8\n",
      "3 0.6 9\n",
      "3 0.6 10\n",
      "3 0.6 20\n",
      "3 0.6 30\n",
      "3 0.6 40\n",
      "3 0.6 50\n",
      "3 0.6 70\n",
      "3 0.6 90\n",
      "3 0.7 1\n",
      "3 0.7 2\n",
      "3 0.7 3\n",
      "3 0.7 4\n",
      "3 0.7 5\n",
      "3 0.7 6\n",
      "3 0.7 7\n",
      "3 0.7 8\n",
      "3 0.7 9\n",
      "3 0.7 10\n",
      "3 0.7 20\n",
      "3 0.7 30\n",
      "3 0.7 40\n",
      "3 0.7 50\n",
      "3 0.7 70\n",
      "3 0.7 90\n",
      "3 0.8 1\n",
      "3 0.8 2\n",
      "3 0.8 3\n",
      "3 0.8 4\n",
      "3 0.8 5\n",
      "3 0.8 6\n",
      "3 0.8 7\n",
      "3 0.8 8\n",
      "3 0.8 9\n",
      "3 0.8 10\n",
      "3 0.8 20\n",
      "3 0.8 30\n",
      "3 0.8 40\n",
      "3 0.8 50\n",
      "3 0.8 70\n",
      "3 0.8 90\n",
      "5 0.1 1\n",
      "5 0.1 2\n",
      "5 0.1 3\n",
      "5 0.1 4\n",
      "5 0.1 5\n",
      "5 0.1 6\n",
      "5 0.1 7\n",
      "5 0.1 8\n",
      "5 0.1 9\n",
      "5 0.1 10\n",
      "5 0.1 20\n",
      "5 0.1 30\n",
      "5 0.1 40\n",
      "5 0.1 50\n",
      "5 0.1 70\n",
      "5 0.1 90\n",
      "5 0.2 1\n",
      "5 0.2 2\n",
      "5 0.2 3\n",
      "5 0.2 4\n",
      "5 0.2 5\n",
      "5 0.2 6\n",
      "5 0.2 7\n",
      "5 0.2 8\n",
      "5 0.2 9\n",
      "5 0.2 10\n",
      "5 0.2 20\n",
      "5 0.2 30\n",
      "5 0.2 40\n",
      "5 0.2 50\n",
      "5 0.2 70\n",
      "5 0.2 90\n",
      "5 0.3 1\n",
      "5 0.3 2\n",
      "5 0.3 3\n",
      "5 0.3 4\n",
      "5 0.3 5\n",
      "5 0.3 6\n",
      "5 0.3 7\n",
      "5 0.3 8\n",
      "5 0.3 9\n",
      "5 0.3 10\n",
      "5 0.3 20\n",
      "5 0.3 30\n",
      "5 0.3 40\n",
      "5 0.3 50\n",
      "5 0.3 70\n",
      "5 0.3 90\n",
      "5 0.4 1\n",
      "5 0.4 2\n",
      "5 0.4 3\n",
      "5 0.4 4\n",
      "5 0.4 5\n",
      "5 0.4 6\n",
      "5 0.4 7\n",
      "5 0.4 8\n",
      "5 0.4 9\n",
      "5 0.4 10\n",
      "5 0.4 20\n",
      "5 0.4 30\n",
      "5 0.4 40\n",
      "5 0.4 50\n",
      "5 0.4 70\n",
      "5 0.4 90\n",
      "5 0.5 1\n",
      "5 0.5 2\n",
      "5 0.5 3\n",
      "5 0.5 4\n",
      "5 0.5 5\n",
      "5 0.5 6\n",
      "5 0.5 7\n",
      "5 0.5 8\n",
      "5 0.5 9\n",
      "5 0.5 10\n",
      "5 0.5 20\n",
      "5 0.5 30\n",
      "5 0.5 40\n",
      "5 0.5 50\n",
      "5 0.5 70\n",
      "5 0.5 90\n",
      "5 0.6 1\n",
      "5 0.6 2\n",
      "5 0.6 3\n",
      "5 0.6 4\n",
      "5 0.6 5\n",
      "5 0.6 6\n",
      "5 0.6 7\n",
      "5 0.6 8\n",
      "5 0.6 9\n",
      "5 0.6 10\n",
      "5 0.6 20\n",
      "5 0.6 30\n",
      "5 0.6 40\n",
      "5 0.6 50\n",
      "5 0.6 70\n",
      "5 0.6 90\n",
      "5 0.7 1\n",
      "5 0.7 2\n",
      "5 0.7 3\n",
      "5 0.7 4\n",
      "5 0.7 5\n",
      "5 0.7 6\n",
      "5 0.7 7\n",
      "5 0.7 8\n",
      "5 0.7 9\n",
      "5 0.7 10\n",
      "5 0.7 20\n",
      "5 0.7 30\n",
      "5 0.7 40\n",
      "5 0.7 50\n",
      "5 0.7 70\n",
      "5 0.7 90\n",
      "5 0.8 1\n",
      "5 0.8 2\n",
      "5 0.8 3\n",
      "5 0.8 4\n",
      "5 0.8 5\n",
      "5 0.8 6\n",
      "5 0.8 7\n",
      "5 0.8 8\n",
      "5 0.8 9\n",
      "5 0.8 10\n",
      "5 0.8 20\n",
      "5 0.8 30\n",
      "5 0.8 40\n",
      "5 0.8 50\n",
      "5 0.8 70\n",
      "5 0.8 90\n",
      "7 0.1 1\n",
      "7 0.1 2\n",
      "7 0.1 3\n",
      "7 0.1 4\n",
      "7 0.1 5\n",
      "7 0.1 6\n",
      "7 0.1 7\n",
      "7 0.1 8\n",
      "7 0.1 9\n",
      "7 0.1 10\n",
      "7 0.1 20\n",
      "7 0.1 30\n",
      "7 0.1 40\n",
      "7 0.1 50\n",
      "7 0.1 70\n",
      "7 0.1 90\n",
      "7 0.2 1\n",
      "7 0.2 2\n",
      "7 0.2 3\n",
      "7 0.2 4\n",
      "7 0.2 5\n",
      "7 0.2 6\n",
      "7 0.2 7\n",
      "7 0.2 8\n",
      "7 0.2 9\n",
      "7 0.2 10\n",
      "7 0.2 20\n",
      "7 0.2 30\n",
      "7 0.2 40\n",
      "7 0.2 50\n",
      "7 0.2 70\n",
      "7 0.2 90\n",
      "7 0.3 1\n",
      "7 0.3 2\n",
      "7 0.3 3\n",
      "7 0.3 4\n",
      "7 0.3 5\n",
      "7 0.3 6\n",
      "7 0.3 7\n",
      "7 0.3 8\n",
      "7 0.3 9\n",
      "7 0.3 10\n",
      "7 0.3 20\n",
      "7 0.3 30\n",
      "7 0.3 40\n",
      "7 0.3 50\n",
      "7 0.3 70\n",
      "7 0.3 90\n",
      "7 0.4 1\n",
      "7 0.4 2\n",
      "7 0.4 3\n",
      "7 0.4 4\n",
      "7 0.4 5\n",
      "7 0.4 6\n",
      "7 0.4 7\n",
      "7 0.4 8\n",
      "7 0.4 9\n",
      "7 0.4 10\n",
      "7 0.4 20\n",
      "7 0.4 30\n",
      "7 0.4 40\n",
      "7 0.4 50\n",
      "7 0.4 70\n",
      "7 0.4 90\n",
      "7 0.5 1\n",
      "7 0.5 2\n",
      "7 0.5 3\n",
      "7 0.5 4\n",
      "7 0.5 5\n",
      "7 0.5 6\n",
      "7 0.5 7\n",
      "7 0.5 8\n",
      "7 0.5 9\n",
      "7 0.5 10\n",
      "7 0.5 20\n",
      "7 0.5 30\n",
      "7 0.5 40\n",
      "7 0.5 50\n",
      "7 0.5 70\n",
      "7 0.5 90\n",
      "7 0.6 1\n",
      "7 0.6 2\n",
      "7 0.6 3\n",
      "7 0.6 4\n",
      "7 0.6 5\n",
      "7 0.6 6\n",
      "7 0.6 7\n",
      "7 0.6 8\n",
      "7 0.6 9\n",
      "7 0.6 10\n",
      "7 0.6 20\n",
      "7 0.6 30\n",
      "7 0.6 40\n",
      "7 0.6 50\n",
      "7 0.6 70\n",
      "7 0.6 90\n",
      "7 0.7 1\n",
      "7 0.7 2\n",
      "7 0.7 3\n",
      "7 0.7 4\n",
      "7 0.7 5\n",
      "7 0.7 6\n",
      "7 0.7 7\n",
      "7 0.7 8\n",
      "7 0.7 9\n",
      "7 0.7 10\n",
      "7 0.7 20\n",
      "7 0.7 30\n",
      "7 0.7 40\n",
      "7 0.7 50\n",
      "7 0.7 70\n",
      "7 0.7 90\n",
      "7 0.8 1\n",
      "7 0.8 2\n",
      "7 0.8 3\n",
      "7 0.8 4\n",
      "7 0.8 5\n",
      "7 0.8 6\n",
      "7 0.8 7\n",
      "7 0.8 8\n",
      "7 0.8 9\n",
      "7 0.8 10\n",
      "7 0.8 20\n",
      "7 0.8 30\n",
      "7 0.8 40\n",
      "7 0.8 50\n",
      "7 0.8 70\n",
      "7 0.8 90\n",
      "9 0.1 1\n",
      "9 0.1 2\n",
      "9 0.1 3\n",
      "9 0.1 4\n",
      "9 0.1 5\n",
      "9 0.1 6\n",
      "9 0.1 7\n",
      "9 0.1 8\n",
      "9 0.1 9\n",
      "9 0.1 10\n",
      "9 0.1 20\n",
      "9 0.1 30\n",
      "9 0.1 40\n",
      "9 0.1 50\n",
      "9 0.1 70\n",
      "9 0.1 90\n",
      "9 0.2 1\n",
      "9 0.2 2\n",
      "9 0.2 3\n",
      "9 0.2 4\n",
      "9 0.2 5\n",
      "9 0.2 6\n",
      "9 0.2 7\n",
      "9 0.2 8\n",
      "9 0.2 9\n",
      "9 0.2 10\n",
      "9 0.2 20\n",
      "9 0.2 30\n",
      "9 0.2 40\n",
      "9 0.2 50\n",
      "9 0.2 70\n",
      "9 0.2 90\n",
      "9 0.3 1\n",
      "9 0.3 2\n",
      "9 0.3 3\n",
      "9 0.3 4\n",
      "9 0.3 5\n",
      "9 0.3 6\n",
      "9 0.3 7\n",
      "9 0.3 8\n",
      "9 0.3 9\n",
      "9 0.3 10\n",
      "9 0.3 20\n",
      "9 0.3 30\n",
      "9 0.3 40\n",
      "9 0.3 50\n",
      "9 0.3 70\n",
      "9 0.3 90\n",
      "9 0.4 1\n",
      "9 0.4 2\n",
      "9 0.4 3\n",
      "9 0.4 4\n",
      "9 0.4 5\n",
      "9 0.4 6\n",
      "9 0.4 7\n",
      "9 0.4 8\n",
      "9 0.4 9\n",
      "9 0.4 10\n",
      "9 0.4 20\n",
      "9 0.4 30\n",
      "9 0.4 40\n",
      "9 0.4 50\n",
      "9 0.4 70\n",
      "9 0.4 90\n",
      "9 0.5 1\n",
      "9 0.5 2\n",
      "9 0.5 3\n",
      "9 0.5 4\n",
      "9 0.5 5\n",
      "9 0.5 6\n",
      "9 0.5 7\n",
      "9 0.5 8\n",
      "9 0.5 9\n",
      "9 0.5 10\n",
      "9 0.5 20\n",
      "9 0.5 30\n",
      "9 0.5 40\n",
      "9 0.5 50\n",
      "9 0.5 70\n",
      "9 0.5 90\n",
      "9 0.6 1\n",
      "9 0.6 2\n",
      "9 0.6 3\n",
      "9 0.6 4\n",
      "9 0.6 5\n",
      "9 0.6 6\n",
      "9 0.6 7\n",
      "9 0.6 8\n",
      "9 0.6 9\n",
      "9 0.6 10\n",
      "9 0.6 20\n",
      "9 0.6 30\n",
      "9 0.6 40\n",
      "9 0.6 50\n",
      "9 0.6 70\n",
      "9 0.6 90\n",
      "9 0.7 1\n",
      "9 0.7 2\n",
      "9 0.7 3\n",
      "9 0.7 4\n",
      "9 0.7 5\n",
      "9 0.7 6\n",
      "9 0.7 7\n",
      "9 0.7 8\n",
      "9 0.7 9\n",
      "9 0.7 10\n",
      "9 0.7 20\n",
      "9 0.7 30\n",
      "9 0.7 40\n",
      "9 0.7 50\n",
      "9 0.7 70\n",
      "9 0.7 90\n",
      "9 0.8 1\n",
      "9 0.8 2\n",
      "9 0.8 3\n",
      "9 0.8 4\n",
      "9 0.8 5\n",
      "9 0.8 6\n",
      "9 0.8 7\n",
      "9 0.8 8\n",
      "9 0.8 9\n",
      "9 0.8 10\n",
      "9 0.8 20\n",
      "9 0.8 30\n",
      "9 0.8 40\n",
      "9 0.8 50\n",
      "9 0.8 70\n",
      "9 0.8 90\n",
      "11 0.1 1\n",
      "11 0.1 2\n",
      "11 0.1 3\n",
      "11 0.1 4\n",
      "11 0.1 5\n",
      "11 0.1 6\n",
      "11 0.1 7\n",
      "11 0.1 8\n",
      "11 0.1 9\n",
      "11 0.1 10\n",
      "11 0.1 20\n",
      "11 0.1 30\n",
      "11 0.1 40\n",
      "11 0.1 50\n",
      "11 0.1 70\n",
      "11 0.1 90\n",
      "11 0.2 1\n",
      "11 0.2 2\n",
      "11 0.2 3\n",
      "11 0.2 4\n",
      "11 0.2 5\n",
      "11 0.2 6\n",
      "11 0.2 7\n",
      "11 0.2 8\n",
      "11 0.2 9\n",
      "11 0.2 10\n",
      "11 0.2 20\n",
      "11 0.2 30\n",
      "11 0.2 40\n",
      "11 0.2 50\n",
      "11 0.2 70\n",
      "11 0.2 90\n",
      "11 0.3 1\n",
      "11 0.3 2\n",
      "11 0.3 3\n",
      "11 0.3 4\n",
      "11 0.3 5\n",
      "11 0.3 6\n",
      "11 0.3 7\n",
      "11 0.3 8\n",
      "11 0.3 9\n",
      "11 0.3 10\n",
      "11 0.3 20\n",
      "11 0.3 30\n",
      "11 0.3 40\n",
      "11 0.3 50\n",
      "11 0.3 70\n",
      "11 0.3 90\n",
      "11 0.4 1\n",
      "11 0.4 2\n",
      "11 0.4 3\n",
      "11 0.4 4\n",
      "11 0.4 5\n",
      "11 0.4 6\n",
      "11 0.4 7\n",
      "11 0.4 8\n",
      "11 0.4 9\n",
      "11 0.4 10\n",
      "11 0.4 20\n",
      "11 0.4 30\n",
      "11 0.4 40\n",
      "11 0.4 50\n",
      "11 0.4 70\n",
      "11 0.4 90\n",
      "11 0.5 1\n",
      "11 0.5 2\n",
      "11 0.5 3\n",
      "11 0.5 4\n",
      "11 0.5 5\n",
      "11 0.5 6\n",
      "11 0.5 7\n",
      "11 0.5 8\n",
      "11 0.5 9\n",
      "11 0.5 10\n",
      "11 0.5 20\n",
      "11 0.5 30\n",
      "11 0.5 40\n",
      "11 0.5 50\n",
      "11 0.5 70\n",
      "11 0.5 90\n",
      "11 0.6 1\n",
      "11 0.6 2\n",
      "11 0.6 3\n",
      "11 0.6 4\n",
      "11 0.6 5\n",
      "11 0.6 6\n",
      "11 0.6 7\n",
      "11 0.6 8\n",
      "11 0.6 9\n",
      "11 0.6 10\n",
      "11 0.6 20\n",
      "11 0.6 30\n",
      "11 0.6 40\n",
      "11 0.6 50\n",
      "11 0.6 70\n",
      "11 0.6 90\n",
      "11 0.7 1\n",
      "11 0.7 2\n",
      "11 0.7 3\n",
      "11 0.7 4\n",
      "11 0.7 5\n",
      "11 0.7 6\n",
      "11 0.7 7\n",
      "11 0.7 8\n",
      "11 0.7 9\n",
      "11 0.7 10\n",
      "11 0.7 20\n",
      "11 0.7 30\n",
      "11 0.7 40\n",
      "11 0.7 50\n",
      "11 0.7 70\n",
      "11 0.7 90\n",
      "11 0.8 1\n",
      "11 0.8 2\n",
      "11 0.8 3\n",
      "11 0.8 4\n",
      "11 0.8 5\n",
      "11 0.8 6\n",
      "11 0.8 7\n",
      "11 0.8 8\n",
      "11 0.8 9\n",
      "11 0.8 10\n",
      "11 0.8 20\n",
      "11 0.8 30\n",
      "11 0.8 40\n",
      "11 0.8 50\n",
      "11 0.8 70\n",
      "11 0.8 90\n",
      "13 0.1 1\n",
      "13 0.1 2\n",
      "13 0.1 3\n",
      "13 0.1 4\n",
      "13 0.1 5\n",
      "13 0.1 6\n",
      "13 0.1 7\n",
      "13 0.1 8\n",
      "13 0.1 9\n",
      "13 0.1 10\n",
      "13 0.1 20\n",
      "13 0.1 30\n",
      "13 0.1 40\n",
      "13 0.1 50\n",
      "13 0.1 70\n",
      "13 0.1 90\n",
      "13 0.2 1\n",
      "13 0.2 2\n",
      "13 0.2 3\n",
      "13 0.2 4\n",
      "13 0.2 5\n",
      "13 0.2 6\n",
      "13 0.2 7\n",
      "13 0.2 8\n",
      "13 0.2 9\n",
      "13 0.2 10\n",
      "13 0.2 20\n",
      "13 0.2 30\n",
      "13 0.2 40\n",
      "13 0.2 50\n",
      "13 0.2 70\n",
      "13 0.2 90\n",
      "13 0.3 1\n",
      "13 0.3 2\n",
      "13 0.3 3\n",
      "13 0.3 4\n",
      "13 0.3 5\n",
      "13 0.3 6\n",
      "13 0.3 7\n",
      "13 0.3 8\n",
      "13 0.3 9\n",
      "13 0.3 10\n",
      "13 0.3 20\n",
      "13 0.3 30\n",
      "13 0.3 40\n",
      "13 0.3 50\n",
      "13 0.3 70\n",
      "13 0.3 90\n",
      "13 0.4 1\n",
      "13 0.4 2\n",
      "13 0.4 3\n",
      "13 0.4 4\n",
      "13 0.4 5\n",
      "13 0.4 6\n",
      "13 0.4 7\n",
      "13 0.4 8\n",
      "13 0.4 9\n",
      "13 0.4 10\n",
      "13 0.4 20\n",
      "13 0.4 30\n",
      "13 0.4 40\n",
      "13 0.4 50\n",
      "13 0.4 70\n",
      "13 0.4 90\n",
      "13 0.5 1\n",
      "13 0.5 2\n",
      "13 0.5 3\n",
      "13 0.5 4\n",
      "13 0.5 5\n",
      "13 0.5 6\n",
      "13 0.5 7\n",
      "13 0.5 8\n",
      "13 0.5 9\n",
      "13 0.5 10\n",
      "13 0.5 20\n",
      "13 0.5 30\n",
      "13 0.5 40\n",
      "13 0.5 50\n",
      "13 0.5 70\n",
      "13 0.5 90\n",
      "13 0.6 1\n",
      "13 0.6 2\n",
      "13 0.6 3\n",
      "13 0.6 4\n",
      "13 0.6 5\n",
      "13 0.6 6\n",
      "13 0.6 7\n",
      "13 0.6 8\n",
      "13 0.6 9\n",
      "13 0.6 10\n",
      "13 0.6 20\n",
      "13 0.6 30\n",
      "13 0.6 40\n",
      "13 0.6 50\n",
      "13 0.6 70\n",
      "13 0.6 90\n",
      "13 0.7 1\n",
      "13 0.7 2\n",
      "13 0.7 3\n",
      "13 0.7 4\n",
      "13 0.7 5\n",
      "13 0.7 6\n",
      "13 0.7 7\n",
      "13 0.7 8\n",
      "13 0.7 9\n",
      "13 0.7 10\n",
      "13 0.7 20\n",
      "13 0.7 30\n",
      "13 0.7 40\n",
      "13 0.7 50\n",
      "13 0.7 70\n",
      "13 0.7 90\n",
      "13 0.8 1\n",
      "13 0.8 2\n",
      "13 0.8 3\n",
      "13 0.8 4\n",
      "13 0.8 5\n",
      "13 0.8 6\n",
      "13 0.8 7\n",
      "13 0.8 8\n",
      "13 0.8 9\n",
      "13 0.8 10\n",
      "13 0.8 20\n",
      "13 0.8 30\n",
      "13 0.8 40\n",
      "13 0.8 50\n",
      "13 0.8 70\n",
      "13 0.8 90\n",
      "15 0.1 1\n",
      "15 0.1 2\n",
      "15 0.1 3\n",
      "15 0.1 4\n",
      "15 0.1 5\n",
      "15 0.1 6\n",
      "15 0.1 7\n",
      "15 0.1 8\n",
      "15 0.1 9\n",
      "15 0.1 10\n",
      "15 0.1 20\n",
      "15 0.1 30\n",
      "15 0.1 40\n",
      "15 0.1 50\n",
      "15 0.1 70\n",
      "15 0.1 90\n",
      "15 0.2 1\n",
      "15 0.2 2\n",
      "15 0.2 3\n",
      "15 0.2 4\n",
      "15 0.2 5\n",
      "15 0.2 6\n",
      "15 0.2 7\n",
      "15 0.2 8\n",
      "15 0.2 9\n",
      "15 0.2 10\n",
      "15 0.2 20\n",
      "15 0.2 30\n",
      "15 0.2 40\n",
      "15 0.2 50\n",
      "15 0.2 70\n",
      "15 0.2 90\n",
      "15 0.3 1\n",
      "15 0.3 2\n",
      "15 0.3 3\n",
      "15 0.3 4\n",
      "15 0.3 5\n",
      "15 0.3 6\n",
      "15 0.3 7\n",
      "15 0.3 8\n",
      "15 0.3 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.3 10\n",
      "15 0.3 20\n",
      "15 0.3 30\n",
      "15 0.3 40\n",
      "15 0.3 50\n",
      "15 0.3 70\n",
      "15 0.3 90\n",
      "15 0.4 1\n",
      "15 0.4 2\n",
      "15 0.4 3\n",
      "15 0.4 4\n",
      "15 0.4 5\n",
      "15 0.4 6\n",
      "15 0.4 7\n",
      "15 0.4 8\n",
      "15 0.4 9\n",
      "15 0.4 10\n",
      "15 0.4 20\n",
      "15 0.4 30\n",
      "15 0.4 40\n",
      "15 0.4 50\n",
      "15 0.4 70\n",
      "15 0.4 90\n",
      "15 0.5 1\n",
      "15 0.5 2\n",
      "15 0.5 3\n",
      "15 0.5 4\n",
      "15 0.5 5\n",
      "15 0.5 6\n",
      "15 0.5 7\n",
      "15 0.5 8\n",
      "15 0.5 9\n",
      "15 0.5 10\n",
      "15 0.5 20\n",
      "15 0.5 30\n",
      "15 0.5 40\n",
      "15 0.5 50\n",
      "15 0.5 70\n",
      "15 0.5 90\n",
      "15 0.6 1\n",
      "15 0.6 2\n",
      "15 0.6 3\n",
      "15 0.6 4\n",
      "15 0.6 5\n",
      "15 0.6 6\n",
      "15 0.6 7\n",
      "15 0.6 8\n",
      "15 0.6 9\n",
      "15 0.6 10\n",
      "15 0.6 20\n",
      "15 0.6 30\n",
      "15 0.6 40\n",
      "15 0.6 50\n",
      "15 0.6 70\n",
      "15 0.6 90\n",
      "15 0.7 1\n",
      "15 0.7 2\n",
      "15 0.7 3\n",
      "15 0.7 4\n",
      "15 0.7 5\n",
      "15 0.7 6\n",
      "15 0.7 7\n",
      "15 0.7 8\n",
      "15 0.7 9\n",
      "15 0.7 10\n",
      "15 0.7 20\n",
      "15 0.7 30\n",
      "15 0.7 40\n",
      "15 0.7 50\n",
      "15 0.7 70\n",
      "15 0.7 90\n",
      "15 0.8 1\n",
      "15 0.8 2\n",
      "15 0.8 3\n",
      "15 0.8 4\n",
      "15 0.8 5\n",
      "15 0.8 6\n",
      "15 0.8 7\n",
      "15 0.8 8\n",
      "15 0.8 9\n",
      "15 0.8 10\n",
      "15 0.8 20\n",
      "15 0.8 30\n",
      "15 0.8 40\n",
      "15 0.8 50\n",
      "15 0.8 70\n",
      "15 0.8 90\n",
      "17 0.1 1\n",
      "17 0.1 2\n",
      "17 0.1 3\n",
      "17 0.1 4\n",
      "17 0.1 5\n",
      "17 0.1 6\n",
      "17 0.1 7\n",
      "17 0.1 8\n",
      "17 0.1 9\n",
      "17 0.1 10\n",
      "17 0.1 20\n",
      "17 0.1 30\n",
      "17 0.1 40\n",
      "17 0.1 50\n",
      "17 0.1 70\n",
      "17 0.1 90\n",
      "17 0.2 1\n",
      "17 0.2 2\n",
      "17 0.2 3\n",
      "17 0.2 4\n",
      "17 0.2 5\n",
      "17 0.2 6\n",
      "17 0.2 7\n",
      "17 0.2 8\n",
      "17 0.2 9\n",
      "17 0.2 10\n",
      "17 0.2 20\n",
      "17 0.2 30\n",
      "17 0.2 40\n",
      "17 0.2 50\n",
      "17 0.2 70\n",
      "17 0.2 90\n",
      "17 0.3 1\n",
      "17 0.3 2\n",
      "17 0.3 3\n",
      "17 0.3 4\n",
      "17 0.3 5\n",
      "17 0.3 6\n",
      "17 0.3 7\n",
      "17 0.3 8\n",
      "17 0.3 9\n",
      "17 0.3 10\n",
      "17 0.3 20\n",
      "17 0.3 30\n",
      "17 0.3 40\n",
      "17 0.3 50\n",
      "17 0.3 70\n",
      "17 0.3 90\n",
      "17 0.4 1\n",
      "17 0.4 2\n",
      "17 0.4 3\n",
      "17 0.4 4\n",
      "17 0.4 5\n",
      "17 0.4 6\n",
      "17 0.4 7\n",
      "17 0.4 8\n",
      "17 0.4 9\n",
      "17 0.4 10\n",
      "17 0.4 20\n",
      "17 0.4 30\n",
      "17 0.4 40\n",
      "17 0.4 50\n",
      "17 0.4 70\n",
      "17 0.4 90\n",
      "17 0.5 1\n",
      "17 0.5 2\n",
      "17 0.5 3\n",
      "17 0.5 4\n",
      "17 0.5 5\n",
      "17 0.5 6\n",
      "17 0.5 7\n",
      "17 0.5 8\n",
      "17 0.5 9\n",
      "17 0.5 10\n",
      "17 0.5 20\n",
      "17 0.5 30\n",
      "17 0.5 40\n",
      "17 0.5 50\n",
      "17 0.5 70\n",
      "17 0.5 90\n",
      "17 0.6 1\n",
      "17 0.6 2\n",
      "17 0.6 3\n",
      "17 0.6 4\n",
      "17 0.6 5\n",
      "17 0.6 6\n",
      "17 0.6 7\n",
      "17 0.6 8\n",
      "17 0.6 9\n",
      "17 0.6 10\n",
      "17 0.6 20\n",
      "17 0.6 30\n",
      "17 0.6 40\n",
      "17 0.6 50\n",
      "17 0.6 70\n",
      "17 0.6 90\n",
      "17 0.7 1\n",
      "17 0.7 2\n",
      "17 0.7 3\n",
      "17 0.7 4\n",
      "17 0.7 5\n",
      "17 0.7 6\n",
      "17 0.7 7\n",
      "17 0.7 8\n",
      "17 0.7 9\n",
      "17 0.7 10\n",
      "17 0.7 20\n",
      "17 0.7 30\n",
      "17 0.7 40\n",
      "17 0.7 50\n",
      "17 0.7 70\n",
      "17 0.7 90\n",
      "17 0.8 1\n",
      "17 0.8 2\n",
      "17 0.8 3\n",
      "17 0.8 4\n",
      "17 0.8 5\n",
      "17 0.8 6\n",
      "17 0.8 7\n",
      "17 0.8 8\n",
      "17 0.8 9\n",
      "17 0.8 10\n",
      "17 0.8 20\n",
      "17 0.8 30\n",
      "17 0.8 40\n",
      "17 0.8 50\n",
      "17 0.8 70\n",
      "17 0.8 90\n",
      "19 0.1 1\n",
      "19 0.1 2\n",
      "19 0.1 3\n",
      "19 0.1 4\n",
      "19 0.1 5\n",
      "19 0.1 6\n",
      "19 0.1 7\n",
      "19 0.1 8\n",
      "19 0.1 9\n",
      "19 0.1 10\n",
      "19 0.1 20\n",
      "19 0.1 30\n",
      "19 0.1 40\n",
      "19 0.1 50\n",
      "19 0.1 70\n",
      "19 0.1 90\n",
      "19 0.2 1\n",
      "19 0.2 2\n",
      "19 0.2 3\n",
      "19 0.2 4\n",
      "19 0.2 5\n",
      "19 0.2 6\n",
      "19 0.2 7\n",
      "19 0.2 8\n",
      "19 0.2 9\n",
      "19 0.2 10\n",
      "19 0.2 20\n",
      "19 0.2 30\n",
      "19 0.2 40\n",
      "19 0.2 50\n",
      "19 0.2 70\n",
      "19 0.2 90\n",
      "19 0.3 1\n",
      "19 0.3 2\n",
      "19 0.3 3\n",
      "19 0.3 4\n",
      "19 0.3 5\n",
      "19 0.3 6\n",
      "19 0.3 7\n",
      "19 0.3 8\n",
      "19 0.3 9\n",
      "19 0.3 10\n",
      "19 0.3 20\n",
      "19 0.3 30\n",
      "19 0.3 40\n",
      "19 0.3 50\n",
      "19 0.3 70\n",
      "19 0.3 90\n",
      "19 0.4 1\n",
      "19 0.4 2\n",
      "19 0.4 3\n",
      "19 0.4 4\n",
      "19 0.4 5\n",
      "19 0.4 6\n",
      "19 0.4 7\n",
      "19 0.4 8\n",
      "19 0.4 9\n",
      "19 0.4 10\n",
      "19 0.4 20\n",
      "19 0.4 30\n",
      "19 0.4 40\n",
      "19 0.4 50\n",
      "19 0.4 70\n",
      "19 0.4 90\n",
      "19 0.5 1\n",
      "19 0.5 2\n",
      "19 0.5 3\n",
      "19 0.5 4\n",
      "19 0.5 5\n",
      "19 0.5 6\n",
      "19 0.5 7\n",
      "19 0.5 8\n",
      "19 0.5 9\n",
      "19 0.5 10\n",
      "19 0.5 20\n",
      "19 0.5 30\n",
      "19 0.5 40\n",
      "19 0.5 50\n",
      "19 0.5 70\n",
      "19 0.5 90\n",
      "19 0.6 1\n",
      "19 0.6 2\n",
      "19 0.6 3\n",
      "19 0.6 4\n",
      "19 0.6 5\n",
      "19 0.6 6\n",
      "19 0.6 7\n",
      "19 0.6 8\n",
      "19 0.6 9\n",
      "19 0.6 10\n",
      "19 0.6 20\n",
      "19 0.6 30\n",
      "19 0.6 40\n",
      "19 0.6 50\n",
      "19 0.6 70\n",
      "19 0.6 90\n",
      "19 0.7 1\n",
      "19 0.7 2\n",
      "19 0.7 3\n",
      "19 0.7 4\n",
      "19 0.7 5\n",
      "19 0.7 6\n",
      "19 0.7 7\n",
      "19 0.7 8\n",
      "19 0.7 9\n",
      "19 0.7 10\n",
      "19 0.7 20\n",
      "19 0.7 30\n",
      "19 0.7 40\n",
      "19 0.7 50\n",
      "19 0.7 70\n",
      "19 0.7 90\n",
      "19 0.8 1\n",
      "19 0.8 2\n",
      "19 0.8 3\n",
      "19 0.8 4\n",
      "19 0.8 5\n",
      "19 0.8 6\n",
      "19 0.8 7\n",
      "19 0.8 8\n",
      "19 0.8 9\n",
      "19 0.8 10\n",
      "19 0.8 20\n",
      "19 0.8 30\n",
      "19 0.8 40\n",
      "19 0.8 50\n",
      "19 0.8 70\n",
      "19 0.8 90\n"
     ]
    }
   ],
   "source": [
    "depths = np.arange(1, 20, 2)\n",
    "nums_feature = np.arange(0.1, 0.9, 0.1)\n",
    "nums_leaf = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,70,90]\n",
    "preds = {}\n",
    "\n",
    "for depth in depths:\n",
    "    for num_feature in nums_feature:\n",
    "        for num_leaf in nums_leaf:\n",
    "            clf = RandomForestClassifier(n_estimators=100, max_depth=depth, min_samples_leaf=num_leaf,max_features=num_feature, n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "            print(depth, num_feature, num_leaf)\n",
    "            result = print_score(m, X_train, X_test, y_train, y_test) \n",
    "            preds[str(depth)+str(num_feature)+str(num_leaf)] = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10.11': 0.26241895925608788,\n",
       " '10.12': 0.262403192401862,\n",
       " '10.13': 0.26244958373038096,\n",
       " '10.14': 0.26242829215738689,\n",
       " '10.15': 0.2624070413572252,\n",
       " '10.16': 0.26241086177160561,\n",
       " '10.17': 0.26242607819259645,\n",
       " '10.18': 0.26242792927918002,\n",
       " '10.19': 0.26242358289526357,\n",
       " '10.110': 0.26243159883408135,\n",
       " '10.120': 0.26246024582601074,\n",
       " '10.130': 0.26242792927918002,\n",
       " '10.140': 0.26240667847901833,\n",
       " '10.150': 0.26242031291411816,\n",
       " '10.170': 0.26240688642046278,\n",
       " '10.190': 0.26242792927918002,\n",
       " '10.21': 0.26242599664693195,\n",
       " '10.22': 0.26243372309864088,\n",
       " '10.23': 0.2624290301456505,\n",
       " '10.24': 0.26242389684607187,\n",
       " '10.25': 0.26246271665964438,\n",
       " '10.26': 0.26241623970817762,\n",
       " '10.27': 0.26242903830021669,\n",
       " '10.28': 0.26243216965373262,\n",
       " '10.29': 0.26243468941476494,\n",
       " '10.210': 0.26240351858451993,\n",
       " '10.220': 0.26244884574211741,\n",
       " '10.230': 0.26243227566309651,\n",
       " '10.240': 0.26242643291623685,\n",
       " '10.250': 0.26243539070747918,\n",
       " '10.270': 0.26241971355348437,\n",
       " '10.290': 0.26239177193155244,\n",
       " '10.31': 0.26242817799345658,\n",
       " '10.32': 0.26242415779219797,\n",
       " '10.33': 0.26242018244105508,\n",
       " '10.34': 0.26242792520189673,\n",
       " '10.35': 0.26239947391956214,\n",
       " '10.36': 0.26246050269485394,\n",
       " '10.37': 0.26240719629398768,\n",
       " '10.38': 0.26242764794663764,\n",
       " '10.39': 0.26242792927918002,\n",
       " '10.310': 0.26242185004989343,\n",
       " '10.320': 0.26246262695941347,\n",
       " '10.330': 0.26240760809959313,\n",
       " '10.340': 0.2624309750097481,\n",
       " '10.350': 0.2624282350754219,\n",
       " '10.370': 0.26243457525083452,\n",
       " '10.390': 0.26242660008484919,\n",
       " '10.41': 0.26240728191693524,\n",
       " '10.42': 0.26243768621793412,\n",
       " '10.43': 0.26243499928828984,\n",
       " '10.44': 0.26242494063057703,\n",
       " '10.45': 0.26242816576160699,\n",
       " '10.46': 0.26241770345285498,\n",
       " '10.47': 0.26242810867964195,\n",
       " '10.48': 0.26243461194638357,\n",
       " '10.49': 0.26242792927918002,\n",
       " '10.410': 0.26242792927918002,\n",
       " '10.420': 0.26240738384901602,\n",
       " '10.430': 0.26240354712550246,\n",
       " '10.440': 0.26242803528854369,\n",
       " '10.450': 0.26242705266328697,\n",
       " '10.470': 0.26243716840296483,\n",
       " '10.490': 0.26241620301262863,\n",
       " '10.51': 0.26242821876628891,\n",
       " '10.52': 0.26244067078925382,\n",
       " '10.53': 0.26244767148454895,\n",
       " '10.54': 0.26242984152501181,\n",
       " '10.55': 0.26243398812205038,\n",
       " '10.56': 0.26242812906605795,\n",
       " '10.57': 0.26242472861184951,\n",
       " '10.58': 0.26243911326706243,\n",
       " '10.59': 0.26243240613615954,\n",
       " '10.510': 0.26242748077802536,\n",
       " '10.520': 0.26239303181206869,\n",
       " '10.530': 0.26244588155721377,\n",
       " '10.540': 0.26242951941963732,\n",
       " '10.550': 0.26243446108690421,\n",
       " '10.570': 0.26242602926519787,\n",
       " '10.590': 0.26242516895843748,\n",
       " '10.61': 0.26241590537095327,\n",
       " '10.62': 0.26243683406574048,\n",
       " '10.63': 0.26241384226564218,\n",
       " '10.64': 0.26243198209870428,\n",
       " '10.65': 0.26244431588045597,\n",
       " '10.66': 0.26244154740514691,\n",
       " '10.67': 0.26239796532476939,\n",
       " '10.68': 0.26245836619844454,\n",
       " '10.69': 0.26241899595163681,\n",
       " '10.610': 0.26241789508516666,\n",
       " '10.620': 0.26240176127545062,\n",
       " '10.630': 0.26243394734921821,\n",
       " '10.640': 0.26244146585948247,\n",
       " '10.650': 0.26242746446889242,\n",
       " '10.670': 0.26242797412929553,\n",
       " '10.690': 0.26243893794388395,\n",
       " '10.71': 0.26242792927918002,\n",
       " '10.72': 0.26242816576160699,\n",
       " '10.73': 0.26242792927918002,\n",
       " '10.74': 0.26244085834428216,\n",
       " '10.75': 0.26241243968021333,\n",
       " '10.76': 0.26240243402718244,\n",
       " '10.77': 0.26243013508940405,\n",
       " '10.78': 0.26242806790680956,\n",
       " '10.79': 0.26244482554085885,\n",
       " '10.710': 0.26242519342213688,\n",
       " '10.720': 0.26244060963000571,\n",
       " '10.730': 0.26242225370093269,\n",
       " '10.740': 0.26240721668040373,\n",
       " '10.750': 0.26238426973042089,\n",
       " '10.770': 0.2624253524361827,\n",
       " '10.790': 0.2624277743424176,\n",
       " '10.81': 0.26242397431445297,\n",
       " '10.82': 0.26242792927918002,\n",
       " '10.83': 0.26241149782778866,\n",
       " '10.84': 0.26239815695708085,\n",
       " '10.85': 0.26242011312724023,\n",
       " '10.86': 0.26244177165572424,\n",
       " '10.87': 0.26241904487903567,\n",
       " '10.88': 0.26242824730727143,\n",
       " '10.89': 0.26242797820657859,\n",
       " '10.810': 0.26243499521100649,\n",
       " '10.820': 0.26244113967682453,\n",
       " '10.830': 0.26242803121126057,\n",
       " '10.840': 0.26241469849511923,\n",
       " '10.850': 0.2624339351173684,\n",
       " '10.870': 0.26242192344099147,\n",
       " '10.890': 0.26242739923236086,\n",
       " '30.11': 0.26238899530167714,\n",
       " '30.12': 0.26240741646728166,\n",
       " '30.13': 0.26242750524172476,\n",
       " '30.14': 0.26233745028716354,\n",
       " '30.15': 0.26244503755958659,\n",
       " '30.16': 0.26241243968021333,\n",
       " '30.17': 0.26243396773563427,\n",
       " '30.18': 0.26243320528367131,\n",
       " '30.19': 0.26243421644991077,\n",
       " '30.110': 0.26242477753924809,\n",
       " '30.120': 0.26242463075705208,\n",
       " '30.130': 0.26238907277005852,\n",
       " '30.140': 0.26239863399921803,\n",
       " '30.150': 0.262428948599986,\n",
       " '30.170': 0.26245536531799196,\n",
       " '30.190': 0.26242799043842846,\n",
       " '30.21': 0.26244021821081603,\n",
       " '30.22': 0.26243342545696552,\n",
       " '30.23': 0.26241611331239773,\n",
       " '30.24': 0.26242792927918002,\n",
       " '30.25': 0.26244830346344866,\n",
       " '30.26': 0.26242269812480401,\n",
       " '30.27': 0.26242054531926196,\n",
       " '30.28': 0.26243777184088196,\n",
       " '30.29': 0.26236944065133661,\n",
       " '30.210': 0.26242646553450272,\n",
       " '30.220': 0.2624376372905356,\n",
       " '30.230': 0.26241041327045117,\n",
       " '30.240': 0.26243753535845504,\n",
       " '30.250': 0.26238855903237229,\n",
       " '30.270': 0.26242033737781761,\n",
       " '30.290': 0.26241667597748275,\n",
       " '30.31': 0.26244360643317488,\n",
       " '30.32': 0.26242792927918002,\n",
       " '30.33': 0.26244462167669774,\n",
       " '30.34': 0.26242839816675079,\n",
       " '30.35': 0.26241467810870317,\n",
       " '30.36': 0.26242354212243124,\n",
       " '30.37': 0.26246170141612152,\n",
       " '30.38': 0.26243091792778284,\n",
       " '30.39': 0.26243022478963496,\n",
       " '30.310': 0.26240031791718932,\n",
       " '30.320': 0.26243288725557989,\n",
       " '30.330': 0.26244384291560185,\n",
       " '30.340': 0.26245359985435623,\n",
       " '30.350': 0.26242436981092576,\n",
       " '30.370': 0.26242493247601051,\n",
       " '30.390': 0.26242761940565484,\n",
       " '30.41': 0.26243092200506624,\n",
       " '30.42': 0.26242980482946282,\n",
       " '30.43': 0.2624312604195736,\n",
       " '30.44': 0.26244354119664337,\n",
       " '30.45': 0.26242157687191753,\n",
       " '30.46': 0.26242947864680494,\n",
       " '30.47': 0.26244584486166478,\n",
       " '30.48': 0.26243565573088895,\n",
       " '30.49': 0.26240394262197514,\n",
       " '30.410': 0.26243467310563195,\n",
       " '30.420': 0.262426979272189,\n",
       " '30.430': 0.2624233015627212,\n",
       " '30.440': 0.26244454828559949,\n",
       " '30.450': 0.26245406058736048,\n",
       " '30.470': 0.26241905711088526,\n",
       " '30.490': 0.26242857348992932,\n",
       " '30.51': 0.2624259151012675,\n",
       " '30.52': 0.26242354619971459,\n",
       " '30.53': 0.26243062436339087,\n",
       " '30.54': 0.26241381780194278,\n",
       " '30.55': 0.26242631467502336,\n",
       " '30.56': 0.26241774830297043,\n",
       " '30.57': 0.26241816418585923,\n",
       " '30.58': 0.26243565980817202,\n",
       " '30.59': 0.26244011220145236,\n",
       " '30.510': 0.26242792927918002,\n",
       " '30.520': 0.26243707462545079,\n",
       " '30.530': 0.26242499363525895,\n",
       " '30.540': 0.26239044273722151,\n",
       " '30.550': 0.26242118137544479,\n",
       " '30.570': 0.26243045719477859,\n",
       " '30.590': 0.26241902449261961,\n",
       " '30.61': 0.26242805567495997,\n",
       " '30.62': 0.26242792927918002,\n",
       " '30.63': 0.26242893229085307,\n",
       " '30.64': 0.26242671424877928,\n",
       " '30.65': 0.26242979259761323,\n",
       " '30.66': 0.2624167208275982,\n",
       " '30.67': 0.26242434942450971,\n",
       " '30.68': 0.26242576831907155,\n",
       " '30.69': 0.26235879894212266,\n",
       " '30.610': 0.26240964266392197,\n",
       " '30.620': 0.26242942156483989,\n",
       " '30.630': 0.26242335864468624,\n",
       " '30.640': 0.26242648999820217,\n",
       " '30.650': 0.26242112837076281,\n",
       " '30.670': 0.26242606188346351,\n",
       " '30.690': 0.26241083323062309,\n",
       " '30.71': 0.26242507925820652,\n",
       " '30.72': 0.26242960911986823,\n",
       " '30.73': 0.26246024582601074,\n",
       " '30.74': 0.26243348253893062,\n",
       " '30.75': 0.26243952914995128,\n",
       " '30.76': 0.26242803121126057,\n",
       " '30.77': 0.26239658312575653,\n",
       " '30.78': 0.26242801082484452,\n",
       " '30.79': 0.2624296947428158,\n",
       " '30.710': 0.26242814129790759,\n",
       " '30.720': 0.26245531231331004,\n",
       " '30.730': 0.2624367606746425,\n",
       " '30.740': 0.2624201212818067,\n",
       " '30.750': 0.26244552683357342,\n",
       " '30.770': 0.26239362709541936,\n",
       " '30.790': 0.26239506637639731,\n",
       " '30.81': 0.26243674028822644,\n",
       " '30.82': 0.26243408597684775,\n",
       " '30.83': 0.26241307573639605,\n",
       " '30.84': 0.26242821876628891,\n",
       " '30.85': 0.26242788442906456,\n",
       " '30.86': 0.26243194948043863,\n",
       " '30.87': 0.26238094266731038,\n",
       " '30.88': 0.26242044338718146,\n",
       " '30.89': 0.26242724021831532,\n",
       " '30.810': 0.26242799859299465,\n",
       " '30.820': 0.26244347188282852,\n",
       " '30.830': 0.26243361708927698,\n",
       " '30.840': 0.26243270785511802,\n",
       " '30.850': 0.26241892256053884,\n",
       " '30.870': 0.26243455078713512,\n",
       " '30.890': 0.26242578055092108,\n",
       " '50.11': 0.26243117887390921,\n",
       " '50.12': 0.26242635952513882,\n",
       " '50.13': 0.26242792927918002,\n",
       " '50.14': 0.26243036749454757,\n",
       " '50.15': 0.26242792927918002,\n",
       " '50.16': 0.26242920546882903,\n",
       " '50.17': 0.26242578055092108,\n",
       " '50.18': 0.26241183624229614,\n",
       " '50.19': 0.26243264669586985,\n",
       " '50.110': 0.26245943444664915,\n",
       " '50.120': 0.26241113902686486,\n",
       " '50.130': 0.26242809237050901,\n",
       " '50.140': 0.26243341730239905,\n",
       " '50.150': 0.26243383726257097,\n",
       " '50.170': 0.26244571031131836,\n",
       " '50.190': 0.26242134446677373,\n",
       " '50.21': 0.26242863464917771,\n",
       " '50.22': 0.26242289383439887,\n",
       " '50.23': 0.26244448712635138,\n",
       " '50.24': 0.26243229604951257,\n",
       " '50.25': 0.26242089596561929,\n",
       " '50.26': 0.2624025033409973,\n",
       " '50.27': 0.26243523577071676,\n",
       " '50.28': 0.26242873250397514,\n",
       " '50.29': 0.26242614342912796,\n",
       " '50.210': 0.26242880181778977,\n",
       " '50.220': 0.26242397023716985,\n",
       " '50.230': 0.26238789035792365,\n",
       " '50.240': 0.26243647526481673,\n",
       " '50.250': 0.26243722956221321,\n",
       " '50.270': 0.26242997607535823,\n",
       " '50.290': 0.26242973959293125,\n",
       " '50.31': 0.26241700623742376,\n",
       " '50.32': 0.26245326551713188,\n",
       " '50.33': 0.26242792927918002,\n",
       " '50.34': 0.26240992399646434,\n",
       " '50.35': 0.26241486566373123,\n",
       " '50.36': 0.26242042300076512,\n",
       " '50.37': 0.26242652261646782,\n",
       " '50.38': 0.26242664493496465,\n",
       " '50.39': 0.26243498297915685,\n",
       " '50.310': 0.26241768306643892,\n",
       " '50.320': 0.26242958057888544,\n",
       " '50.330': 0.26240453382804252,\n",
       " '50.340': 0.26243338876141653,\n",
       " '50.350': 0.26242720760004939,\n",
       " '50.370': 0.26243128896055617,\n",
       " '50.390': 0.26242704450872051,\n",
       " '50.41': 0.26241796847626464,\n",
       " '50.42': 0.26242798228386199,\n",
       " '50.43': 0.26245007300436779,\n",
       " '50.44': 0.26243198617598767,\n",
       " '50.45': 0.26242461852520221,\n",
       " '50.46': 0.26242280821145098,\n",
       " '50.47': 0.26240357566648498,\n",
       " '50.48': 0.26242789258363103,\n",
       " '50.49': 0.26244224869786154,\n",
       " '50.410': 0.26242326894445528,\n",
       " '50.420': 0.26242799451571158,\n",
       " '50.430': 0.26242810460235855,\n",
       " '50.440': 0.262432230812981,\n",
       " '50.450': 0.26243982271434352,\n",
       " '50.470': 0.26242792927918002,\n",
       " '50.490': 0.26241402574338718,\n",
       " '50.51': 0.26243139089263695,\n",
       " '50.52': 0.26243327052020304,\n",
       " '50.53': 0.26238774357572764,\n",
       " '50.54': 0.26243634479175365,\n",
       " '50.55': 0.26241827834978959,\n",
       " '50.56': 0.26242813314334107,\n",
       " '50.57': 0.26243932936307329,\n",
       " '50.58': 0.26243167630246245,\n",
       " '50.59': 0.26244133538641939,\n",
       " '50.510': 0.26242903830021669,\n",
       " '50.520': 0.26242605372889705,\n",
       " '50.530': 0.26243713578469891,\n",
       " '50.540': 0.26242246164237709,\n",
       " '50.550': 0.26242315478052519,\n",
       " '50.570': 0.2624282065344391,\n",
       " '50.590': 0.26243122780130801,\n",
       " '50.61': 0.26242803121126057,\n",
       " '50.62': 0.26241526931477044,\n",
       " '50.63': 0.26245089253829557,\n",
       " '50.64': 0.26242895267726912,\n",
       " '50.65': 0.26241597060748506,\n",
       " '50.66': 0.26239867069476708,\n",
       " '50.67': 0.26241883286030793,\n",
       " '50.68': 0.26240955704097413,\n",
       " '50.69': 0.26242792927918002,\n",
       " '50.610': 0.26242997607535823,\n",
       " '50.620': 0.26238927255693645,\n",
       " '50.630': 0.26242792927918002,\n",
       " '50.640': 0.26242366036364467,\n",
       " '50.650': 0.26234237564529778,\n",
       " '50.670': 0.26242854902622992,\n",
       " '50.690': 0.26242810460235855,\n",
       " '50.71': 0.26242655115745028,\n",
       " '50.72': 0.26243725402591239,\n",
       " '50.73': 0.26245166722210816,\n",
       " '50.74': 0.26243057543599224,\n",
       " '50.75': 0.26242798228386199,\n",
       " '50.76': 0.26243923558555926,\n",
       " '50.77': 0.2624212751529591,\n",
       " '50.78': 0.26242659600756579,\n",
       " '50.79': 0.26241665151378329,\n",
       " '50.710': 0.26242477346196497,\n",
       " '50.720': 0.26242931963275934,\n",
       " '50.730': 0.2624295112650708,\n",
       " '50.740': 0.26243402074031619,\n",
       " '50.750': 0.26242906684119949,\n",
       " '50.770': 0.2624282350754219,\n",
       " '50.790': 0.26238935410260089,\n",
       " '50.81': 0.26242744408247631,\n",
       " '50.82': 0.26241716525146958,\n",
       " '50.83': 0.26241285556310207,\n",
       " '50.84': 0.26241174246478211,\n",
       " '50.85': 0.26241640279950651,\n",
       " '50.86': 0.2624395576909338,\n",
       " '50.87': 0.26241575043419085,\n",
       " '50.88': 0.26243230420407904,\n",
       " '50.89': 0.26245189554996856,\n",
       " '50.810': 0.26245998487988431,\n",
       " '50.820': 0.26242500178982547,\n",
       " '50.830': 0.26242576831907155,\n",
       " '50.840': 0.26240081534574267,\n",
       " '50.850': 0.26242965804726681,\n",
       " '50.870': 0.26242470822543323,\n",
       " '50.890': 0.26242662862583166,\n",
       " '70.11': 0.26242308546671034,\n",
       " '70.12': 0.2624248427757796,\n",
       " '70.13': 0.26242067986960843,\n",
       " '70.14': 0.26242553183664435,\n",
       " '70.15': 0.26242797412929553,\n",
       " '70.16': 0.26244202852456749,\n",
       " '70.17': 0.26242842263044996,\n",
       " '70.18': 0.26240105998273605,\n",
       " '70.19': 0.26242792927918002,\n",
       " '70.110': 0.26244048323422575,\n",
       " '70.120': 0.26242342388121775,\n",
       " '70.130': 0.26242096527943393,\n",
       " '70.140': 0.26242792927918002,\n",
       " '70.150': 0.2624291076140316,\n",
       " '70.170': 0.26242732176397982,\n",
       " '70.190': 0.26242273889763612,\n",
       " '70.21': 0.26241738134748044,\n",
       " '70.22': 0.2624579503155558,\n",
       " '70.23': 0.26240856218386754,\n",
       " '70.24': 0.26241416029373354,\n",
       " '70.25': 0.2624266897850801,\n",
       " '70.26': 0.262430261485184,\n",
       " '70.27': 0.26242709343611909,\n",
       " '70.28': 0.2624135976286488,\n",
       " '70.29': 0.26242751747357435,\n",
       " '70.210': 0.26243816326007141,\n",
       " '70.220': 0.26242839816675079,\n",
       " '70.230': 0.26241332852795596,\n",
       " '70.240': 0.26244280728566322,\n",
       " '70.250': 0.26242781919253305,\n",
       " '70.270': 0.26246067801803247,\n",
       " '70.290': 0.26242636360242222,\n",
       " '70.31': 0.26242945010582236,\n",
       " '70.32': 0.2624226084245731,\n",
       " '70.33': 0.26241913050198329,\n",
       " '70.34': 0.26243726625776226,\n",
       " '70.35': 0.26242426380156186,\n",
       " '70.36': 0.26242840632131731,\n",
       " '70.37': 0.26241404205252011,\n",
       " '70.38': 0.26242792927918002,\n",
       " '70.39': 0.26242500994439188,\n",
       " '70.310': 0.2624488008920019,\n",
       " '70.320': 0.26242824730727143,\n",
       " '70.330': 0.26242797005201218,\n",
       " '70.340': 0.26242887113160462,\n",
       " '70.350': 0.26245903079561017,\n",
       " '70.370': 0.26241957492585455,\n",
       " '70.390': 0.26240664993803553,\n",
       " '70.41': 0.26245488012128854,\n",
       " '70.42': 0.2624366546652786,\n",
       " '70.43': 0.2624203944597826,\n",
       " '70.44': 0.26242809644779208,\n",
       " '70.45': 0.26244740238385611,\n",
       " '70.46': 0.26243069367720573,\n",
       " '70.47': 0.26242207430047082,\n",
       " '70.48': 0.2624283614712018,\n",
       " '70.49': 0.26245297603002299,\n",
       " '70.410': 0.26242772133773562,\n",
       " '70.420': 0.26242601295606494,\n",
       " '70.430': 0.26241979102186547,\n",
       " '70.440': 0.26242792927918002,\n",
       " '70.450': 0.2624532247442995,\n",
       " '70.470': 0.26245589536481118,\n",
       " '70.490': 0.26242476123011516,\n",
       " '70.51': 0.26244173496017525,\n",
       " '70.52': 0.2624404587705263,\n",
       " '70.53': 0.26243248360454091,\n",
       " '70.54': 0.26242507110364033,\n",
       " '70.55': 0.26242539320901481,\n",
       " '70.56': 0.26242741961877691,\n",
       " '70.57': 0.26240368167584882,\n",
       " '70.58': 0.26244802620818936,\n",
       " '70.59': 0.26243304626962571,\n",
       " '70.510': 0.26247040233852093,\n",
       " '70.520': 0.26241254976686029,\n",
       " '70.530': 0.26241912642470017,\n",
       " '70.540': 0.26242830438923653,\n",
       " '70.550': 0.26243074260460431,\n",
       " '70.570': 0.26242379083670803,\n",
       " '70.590': 0.26244329655964999,\n",
       " '70.61': 0.26243285871459732,\n",
       " '70.62': 0.26242788850634768,\n",
       " '70.63': 0.26242862241732789,\n",
       " '70.64': 0.26243214926731656,\n",
       " '70.65': 0.26240682933849746,\n",
       " '70.66': 0.26242763163750471,\n",
       " '70.67': 0.26244690903258627,\n",
       " '70.68': 0.26239830781655998,\n",
       " '70.69': 0.2624257193916727,\n",
       " '70.610': 0.26244214676578098,\n",
       " '70.620': 0.26242025583215312,\n",
       " '70.630': 0.26242978852032983,\n",
       " '70.640': 0.26242772541501874,\n",
       " '70.650': 0.26243769437250064,\n",
       " '70.670': 0.26242794558831301,\n",
       " '70.690': 0.26243481173326144,\n",
       " '70.71': 0.26242604965161392,\n",
       " '70.72': 0.26242854902622992,\n",
       " '70.73': 0.26242793335646314,\n",
       " '70.74': 0.26242927478264388,\n",
       " '70.75': 0.26243010654842147,\n",
       " '70.76': 0.26242800267027805,\n",
       " '70.77': 0.26242792927918002,\n",
       " '70.78': 0.26242977221119718,\n",
       " '70.79': 0.26243439177308958,\n",
       " '70.710': 0.26242544213641361,\n",
       " '70.720': 0.2624367565973591,\n",
       " '70.730': 0.26242990268426025,\n",
       " '70.740': 0.26243042049922954,\n",
       " '70.750': 0.26242440650647475,\n",
       " '70.770': 0.26244765517541602,\n",
       " '70.790': 0.26243007393015566,\n",
       " '70.81': 0.26242115691174539,\n",
       " '70.82': 0.26242709751340243,\n",
       " '70.83': 0.26243538663019611,\n",
       " '70.84': 0.26244822191778416,\n",
       " '70.85': 0.26246360958467019,\n",
       " '70.86': 0.26242927885992701,\n",
       " '70.87': 0.26244485000455825,\n",
       " '70.88': 0.26243585144048348,\n",
       " '70.89': 0.26244193882433658,\n",
       " '70.810': 0.26242593548768356,\n",
       " '70.820': 0.26241430299864643,\n",
       " '70.830': 0.26242269812480401,\n",
       " '70.840': 0.26236016483200258,\n",
       " '70.850': 0.26234993900567771,\n",
       " '70.870': 0.2624282309981385,\n",
       " '70.890': 0.26242953165148686,\n",
       " '90.11': 0.26242806790680956,\n",
       " '90.12': 0.26242940117842384,\n",
       " '90.13': 0.26243047350391147,\n",
       " '90.14': 0.26243945575885325,\n",
       " '90.15': 0.26243879931625413,\n",
       " '90.16': 0.262430261485184,\n",
       " '90.17': 0.26243093423691577,\n",
       " '90.18': 0.26242792927918002,\n",
       " '90.19': 0.26242476938468162,\n",
       " '90.110': 0.26242631875230676,\n",
       " '90.120': 0.26241827427250647,\n",
       " '90.130': 0.26242792927918002,\n",
       " '90.140': 0.26241322251859228,\n",
       " '90.150': 0.26244415278912703,\n",
       " '90.170': 0.26242005196799179,\n",
       " '90.190': 0.26240620143688115,\n",
       " '90.21': 0.26244141285480072,\n",
       " '90.22': 0.26241913050198329,\n",
       " '90.23': 0.26243130119240599,\n",
       " '90.24': 0.26242440242919168,\n",
       " '90.25': 0.26241389119304104,\n",
       " '90.26': 0.26240935317681313,\n",
       " '90.27': 0.26243565980817202,\n",
       " '90.28': 0.26243785338654646,\n",
       " '90.29': 0.26244663177732691,\n",
       " '90.210': 0.26242810867964195,\n",
       " '90.220': 0.26240952034542508,\n",
       " '90.230': 0.2624201212818067,\n",
       " '90.240': 0.26242794151102966,\n",
       " '90.250': 0.26242417002404783,\n",
       " '90.270': 0.26243322974737071,\n",
       " '90.290': 0.26241871869637784,\n",
       " '90.31': 0.26242721167733252,\n",
       " '90.32': 0.26242885889975509,\n",
       " '90.33': 0.26242872434940867,\n",
       " '90.34': 0.26241988072209643,\n",
       " '90.35': 0.26238923586138746,\n",
       " '90.36': 0.26242792927918002,\n",
       " '90.37': 0.26242792927918002,\n",
       " '90.38': 0.262426979272189,\n",
       " '90.39': 0.26242653484831735,\n",
       " '90.310': 0.26244943287090161,\n",
       " '90.320': 0.26242944195125595,\n",
       " '90.330': 0.26241979509914881,\n",
       " '90.340': 0.2624287977405067,\n",
       " '90.350': 0.26243256107292201,\n",
       " '90.370': 0.26241768714372221,\n",
       " '90.390': 0.26242792927918002,\n",
       " '90.41': 0.26242792927918002,\n",
       " '90.42': 0.26240292330116927,\n",
       " '90.43': 0.26242961319715136,\n",
       " '90.44': 0.26242567046427412,\n",
       " '90.45': 0.26245695545844921,\n",
       " '90.46': 0.26241020125172337,\n",
       " '90.47': 0.26242998015264157,\n",
       " '90.48': 0.26242587025115205,\n",
       " '90.49': 0.26243055097229284,\n",
       " '90.410': 0.26242515672658789,\n",
       " '90.420': 0.26245052558280557,\n",
       " '90.430': 0.2623996777837232,\n",
       " '90.440': 0.26240931648126387,\n",
       " '90.450': 0.26244248518028845,\n",
       " '90.470': 0.2624257234689561,\n",
       " '90.490': 0.26238924809323705,\n",
       " '90.51': 0.26244699873281718,\n",
       " '90.52': 0.26241090662172106,\n",
       " '90.53': 0.26241327552327404,\n",
       " '90.54': 0.26242792927918002,\n",
       " '90.55': 0.26243061213154123,\n",
       " '90.56': 0.26242792927918002,\n",
       " '90.57': 0.26243442439135517,\n",
       " '90.58': 0.26242339534023523,\n",
       " '90.59': 0.26242620866565952,\n",
       " '90.510': 0.26243654050134824,\n",
       " '90.520': 0.26243621431869035,\n",
       " '90.530': 0.26242792927918002,\n",
       " '90.540': 0.26245230735557429,\n",
       " '90.550': 0.26240955704097413,\n",
       " '90.570': 0.26243475872857958,\n",
       " '90.590': 0.26244234247537557,\n",
       " '90.61': 0.2624418205831231,\n",
       " '90.62': 0.26242802713397745,\n",
       " '90.63': 0.26245433376533639,\n",
       " '90.64': 0.26239305627576787,\n",
       " '90.65': 0.26243403297216583,\n",
       " '90.66': 0.26243343361153204,\n",
       " '90.67': 0.26242584171016953,\n",
       " '90.68': 0.26245282109326051,\n",
       " '90.69': 0.26242799043842846,\n",
       " '90.610': 0.26242161356746652,\n",
       " '90.620': 0.26242796597472906,\n",
       " '90.630': 0.26242448805213919,\n",
       " '90.640': 0.26244440150340359,\n",
       " '90.650': 0.26242792927918002,\n",
       " '90.670': 0.26243311558344062,\n",
       " '90.690': 0.26244719444241177,\n",
       " '90.71': 0.26244423025750813,\n",
       " '90.72': 0.26246438834576585,\n",
       " '90.73': 0.26243375163962335,\n",
       " '90.74': 0.26241761375262396,\n",
       " '90.75': 0.2624284634032823,\n",
       " '90.76': 0.26243073037275477,\n",
       " '90.77': 0.2624367606746425,\n",
       " '90.78': 0.2624379349322109,\n",
       " '90.79': 0.26244350450109444,\n",
       " '90.710': 0.26243668728354447,\n",
       " '90.720': 0.26242792927918002,\n",
       " '90.730': 0.26242792927918002,\n",
       " '90.740': 0.26239503375813139,\n",
       " '90.750': 0.26240988322363196,\n",
       " '90.770': 0.26242739107779445,\n",
       " '90.790': 0.26243497074730732,\n",
       " '90.81': 0.2624221273051528,\n",
       " '90.82': 0.26243246321812463,\n",
       " '90.83': 0.26242340757208482,\n",
       " '90.84': 0.26240797097780028,\n",
       " '90.85': 0.26243848128816283,\n",
       " '90.86': 0.26241521631008857,\n",
       " '90.87': 0.2624129493406161,\n",
       " '90.88': 0.26246489800616896,\n",
       " '90.89': 0.26242792927918002,\n",
       " '90.810': 0.26242800267027805,\n",
       " '90.820': 0.26241662705008389,\n",
       " '90.830': 0.26244359827860847,\n",
       " '90.840': 0.26243546002129414,\n",
       " '90.850': 0.26242853271709726,\n",
       " '90.870': 0.2624280230566941,\n",
       " '90.890': 0.26242808013865915,\n",
       " '110.11': 0.26243004538917308,\n",
       " '110.12': 0.26242662862583166,\n",
       " '110.13': 0.26244733714732466,\n",
       " '110.14': 0.2624199092630789,\n",
       " '110.15': 0.26242792927918002,\n",
       " '110.16': 0.26242765610120411,\n",
       " '110.17': 0.2624288996725872,\n",
       " '110.18': 0.26242792927918002,\n",
       " '110.19': 0.26243389842181936,\n",
       " '110.110': 0.26241519592367252,\n",
       " '110.120': 0.26243756389943762,\n",
       " '110.130': 0.26242262881098916,\n",
       " '110.140': 0.26242798636114512,\n",
       " '110.150': 0.2624220702231877,\n",
       " '110.170': 0.26243704200718487,\n",
       " '110.190': 0.26244874381003691,\n",
       " '110.21': 0.26240876604802887,\n",
       " '110.22': 0.26243265077315298,\n",
       " '110.23': 0.26245425629695501,\n",
       " '110.24': 0.26245014639546582,\n",
       " '110.25': 0.26244009996960255,\n",
       " '110.26': 0.26242429641982773,\n",
       " '110.27': 0.26242801897941098,\n",
       " '110.28': 0.26245366916817109,\n",
       " '110.29': 0.26243075891373724,\n",
       " '110.210': 0.26241009524235981,\n",
       " '110.220': 0.26245886362699788,\n",
       " '110.230': 0.2624320595670856,\n",
       " '110.240': 0.26243469349204801,\n",
       " '110.250': 0.26243432653655807,\n",
       " '110.270': 0.26244530666027915,\n",
       " '110.290': 0.2624361980095577,\n",
       " '110.31': 0.26239919258701949,\n",
       " '110.32': 0.26244411609357798,\n",
       " '110.33': 0.26241831096805546,\n",
       " '110.34': 0.26242168695856455,\n",
       " '110.35': 0.26240787312300284,\n",
       " '110.36': 0.26244299484069156,\n",
       " '110.37': 0.26245251937430181,\n",
       " '110.38': 0.26243003315732349,\n",
       " '110.39': 0.26244067078925382,\n",
       " '110.310': 0.26244542490149264,\n",
       " '110.320': 0.26245223804175943,\n",
       " '110.330': 0.26242392130977105,\n",
       " '110.340': 0.26242525050410193,\n",
       " '110.350': 0.2624346527192159,\n",
       " '110.370': 0.26242958465616884,\n",
       " '110.390': 0.26243164776147992,\n",
       " '110.41': 0.26243803278700834,\n",
       " '110.42': 0.26243883193452006,\n",
       " '110.43': 0.26241547317893177,\n",
       " '110.44': 0.2624199908087434,\n",
       " '110.45': 0.26242840224403391,\n",
       " '110.46': 0.26241290449050064,\n",
       " '110.47': 0.26242071656515736,\n",
       " '110.48': 0.26243654457863164,\n",
       " '110.49': 0.26242936448287485,\n",
       " '110.410': 0.26240001212094755,\n",
       " '110.420': 0.2623956657370311,\n",
       " '110.430': 0.26244116821780711,\n",
       " '110.440': 0.26244557983825534,\n",
       " '110.450': 0.26244792019882551,\n",
       " '110.470': 0.26245580566458016,\n",
       " '110.490': 0.26243382503072138,\n",
       " '110.51': 0.26241199933362508,\n",
       " '110.52': 0.26242255134260806,\n",
       " '110.53': 0.26240061148158134,\n",
       " '110.54': 0.26242801897941098,\n",
       " '110.55': 0.26244716997871231,\n",
       " '110.56': 0.26242792927918002,\n",
       " '110.57': 0.26242496509427643,\n",
       " '110.58': 0.26243775145446568,\n",
       " '110.59': 0.26244722298339429,\n",
       " '110.510': 0.26242959688801837,\n",
       " '110.520': 0.26242799043842846,\n",
       " '110.530': 0.26243563126718955,\n",
       " '110.540': 0.26243074260460431,\n",
       " '110.550': 0.26241500429136105,\n",
       " '110.570': 0.26242517303572088,\n",
       " '110.590': 0.26242844709414936,\n",
       " '110.61': 0.26242716682721706,\n",
       " '110.62': 0.26242734622767899,\n",
       " '110.63': 0.26243729479874478,\n",
       " '110.64': 0.26242804752039356,\n",
       " '110.65': 0.26240580594040835,\n",
       " '110.66': 0.26242695480848954,\n",
       " '110.67': 0.26240487631983334,\n",
       " '110.68': 0.26241536716956787,\n",
       " '110.69': 0.26244374098352136,\n",
       " '110.610': 0.26242814129790759,\n",
       " '110.620': 0.26241912234741677,\n",
       " '110.630': 0.26242020690475426,\n",
       " '110.640': 0.26241232551628291,\n",
       " '110.650': 0.2624209571248674,\n",
       " '110.670': 0.26241749143412746,\n",
       " '110.690': 0.26242322817162317,\n",
       " '110.71': 0.2624146658768533,\n",
       " '110.72': 0.26240057070874923,\n",
       " '110.73': 0.26243319305182172,\n",
       " '110.74': 0.26242221292810031,\n",
       " '110.75': 0.26239070368334788,\n",
       " '110.76': 0.26242464298890167,\n",
       " '110.77': 0.26241794401256524,\n",
       " '110.78': 0.26242485500762947,\n",
       " '110.79': 0.262428312543803,\n",
       " '110.710': 0.26242872434940867,\n",
       " '110.720': 0.26243447331875402,\n",
       " '110.730': 0.26246705081171101,\n",
       " '110.740': 0.26242966212454993,\n",
       " '110.750': 0.26242982929316222,\n",
       " '110.770': 0.26242559707317614,\n",
       " '110.790': 0.26242792927918002,\n",
       " '110.81': 0.26242677540802767,\n",
       " '110.82': 0.26243683406574048,\n",
       " '110.83': 0.26243592890886486,\n",
       " '110.84': 0.26242875289039119,\n",
       " '110.85': 0.26244621997172124,\n",
       " '110.86': 0.26244580816611579,\n",
       " '110.87': 0.26243705016175134,\n",
       " '110.88': 0.26241347938743531,\n",
       " '110.89': 0.26237707740281457,\n",
       " '110.810': 0.26242603741976411,\n",
       " '110.820': 0.26242603741976411,\n",
       " '110.830': 0.26243049389032752,\n",
       " '110.840': 0.26243085676853467,\n",
       " '110.850': 0.26243400035389991,\n",
       " '110.870': 0.26244747577495414,\n",
       " '110.890': 0.26245773014226181,\n",
       " '130.11': 0.2624277458014348,\n",
       " '130.12': 0.26244951033928271,\n",
       " '130.13': 0.26242792927918002,\n",
       " '130.14': 0.26240685787947998,\n",
       " '130.15': 0.26241176285119816,\n",
       " '130.16': 0.26241678606412977,\n",
       " '130.17': 0.26244011220145236,\n",
       " '130.18': 0.26243564757632248,\n",
       " '130.19': 0.2624266897850801,\n",
       " '130.110': 0.26241349977385137,\n",
       " '130.120': 0.26242808421594249,\n",
       " '130.130': 0.26241547725621489,\n",
       " '130.140': 0.26245074983338296,\n",
       " '130.150': 0.2624367035926774,\n",
       " '130.170': 0.2624302574079006,\n",
       " '130.190': 0.26242795374287919,\n",
       " '130.21': 0.26243338876141653,\n",
       " '130.22': 0.2624290016046677,\n",
       " '130.23': 0.26241120426339642,\n",
       " '130.24': 0.26243601860909582,\n",
       " '130.25': 0.26243012285755424,\n",
       " '130.26': 0.26246237009057022,\n",
       " '130.27': 0.26242911576859806,\n",
       " '130.28': 0.26244596310287827,\n",
       " '130.29': 0.26242239640584558,\n",
       " '130.210': 0.26240470915122133,\n",
       " '130.220': 0.26243360485742745,\n",
       " '130.230': 0.26242397023716985,\n",
       " '130.240': 0.26244487446825765,\n",
       " '130.250': 0.26242393354162086,\n",
       " '130.270': 0.26242897306368518,\n",
       " '130.290': 0.26243322567008759,\n",
       " '130.31': 0.26243219411743202,\n",
       " '130.32': 0.26243320528367131,\n",
       " '130.33': 0.2624188287830248,\n",
       " '130.34': 0.26241770345285498,\n",
       " '130.35': 0.26243955361365068,\n",
       " '130.36': 0.26243355593002854,\n",
       " '130.37': 0.26242905053206655,\n",
       " '130.38': 0.26242007643169124,\n",
       " '130.39': 0.26240174496631763,\n",
       " '130.310': 0.26240314347446347,\n",
       " '130.320': 0.26242792927918002,\n",
       " '130.330': 0.26243320936095466,\n",
       " '130.340': 0.26242807198409296,\n",
       " '130.350': 0.26243654865591476,\n",
       " '130.370': 0.26242718313635,\n",
       " '130.390': 0.26238992492225222,\n",
       " '130.41': 0.26243778815001467,\n",
       " '130.42': 0.26243347030708097,\n",
       " '130.43': 0.26244637083120059,\n",
       " '130.44': 0.26247467940862251,\n",
       " '130.45': 0.26239989387973406,\n",
       " '130.46': 0.2624268691855417,\n",
       " '130.47': 0.26243553341239212,\n",
       " '130.48': 0.26243511752950333,\n",
       " '130.49': 0.26242375414115898,\n",
       " '130.410': 0.26242801082484452,\n",
       " '130.420': 0.26241252530316084,\n",
       " '130.430': 0.26241640279950651,\n",
       " '130.440': 0.26243499521100649,\n",
       " '130.450': 0.26242298761191291,\n",
       " '130.470': 0.26245450093394873,\n",
       " '130.490': 0.26243484027424396,\n",
       " '130.51': 0.26241213388397144,\n",
       " '130.52': 0.26240740423543207,\n",
       " '130.53': 0.2624202436003033,\n",
       " '130.54': 0.26242970697466539,\n",
       " '130.55': 0.26240316386087953,\n",
       " '130.56': 0.26241723456528443,\n",
       " '130.57': 0.26241995819047775,\n",
       " '130.58': 0.26243356408459506,\n",
       " '130.59': 0.26240513726595971,\n",
       " '130.510': 0.26245104747505804,\n",
       " '130.520': 0.26240527181630607,\n",
       " '130.530': 0.26239204918681175,\n",
       " '130.540': 0.26242461037063602,\n",
       " '130.550': 0.26242006827712477,\n",
       " '130.570': 0.26242111613891322,\n",
       " '130.590': 0.26244791612154239,\n",
       " '130.61': 0.262437992014176,\n",
       " '130.62': 0.26244200406086809,\n",
       " '130.63': 0.2624276927967531,\n",
       " '130.64': 0.26242758271010591,\n",
       " '130.65': 0.26244065855740423,\n",
       " '130.66': 0.26242664493496465,\n",
       " '130.67': 0.26243418790892825,\n",
       " '130.68': 0.26242429234254439,\n",
       " '130.69': 0.26241939552539295,\n",
       " '130.610': 0.26242412109664898,\n",
       " '130.620': 0.26245802778393712,\n",
       " '130.630': 0.26238375191545155,\n",
       " '130.640': 0.26242587432843512,\n",
       " '130.650': 0.26242937263744109,\n",
       " '130.670': 0.26242793743374654,\n",
       " '130.690': 0.26243522761615029,\n",
       " '130.71': 0.2624439244612663,\n",
       " '130.72': 0.26242229447376481,\n",
       " '130.73': 0.26242797412929553,\n",
       " '130.74': 0.26242039038249954,\n",
       " '130.75': 0.26243476688314599,\n",
       " '130.76': 0.2624264369935202,\n",
       " '130.77': 0.26243287094644696,\n",
       " '130.78': 0.26239310520316667,\n",
       " '130.79': 0.26242792927918002,\n",
       " '130.710': 0.26239792047465393,\n",
       " '130.720': 0.26242619643380993,\n",
       " '130.730': 0.26238942341641586,\n",
       " '130.740': 0.26242855718079633,\n",
       " '130.750': 0.26242792927918002,\n",
       " '130.770': 0.26248349041766889,\n",
       " '130.790': 0.26242437388820888,\n",
       " '130.81': 0.26241502060049399,\n",
       " '130.82': 0.26241476780893408,\n",
       " '130.83': 0.26240301707868352,\n",
       " '130.84': 0.26242542582728073,\n",
       " '130.85': 0.2624508843837291,\n",
       " '130.86': 0.26242734622767899,\n",
       " '130.87': 0.26243420421806124,\n",
       " '130.88': 0.26242747670074223,\n",
       " '130.89': 0.26240206299440905,\n",
       " '130.810': 0.26242021913660413,\n",
       " '130.820': 0.26245958938341185,\n",
       " '130.830': 0.262436679128978,\n",
       " '130.840': 0.26242139339417253,\n",
       " '130.850': 0.26244630967195215,\n",
       " '130.870': 0.26241822126782449,\n",
       " '130.890': 0.2624229223753814,\n",
       " '150.11': 0.2624256378460082,\n",
       " '150.12': 0.26241262723524161,\n",
       " '150.13': 0.26241244375749639,\n",
       " '150.14': 0.26242792927918002,\n",
       " '150.15': 0.26241930990244511,\n",
       " '150.16': 0.26243455486441847,\n",
       " '150.17': 0.26241451094009088,\n",
       " '150.18': 0.2624323123586455,\n",
       " '150.19': 0.26243314412442315,\n",
       " '150.110': 0.26243346215251451,\n",
       " '150.120': 0.26242806382952644,\n",
       " '150.130': 0.26242913207773105,\n",
       " '150.140': 0.262435529335109,\n",
       " '150.150': 0.26241997042232734,\n",
       " '150.170': 0.26236762626030202,\n",
       " '150.190': 0.26238813091763391,\n",
       " '150.21': 0.26242701189045459,\n",
       " '150.22': 0.26242150755810262,\n",
       " '150.23': 0.26243014732125364,\n",
       " '150.24': 0.26242272666578659,\n",
       " '150.25': 0.2624420692973996,\n",
       " '150.26': 0.26242288160254901,\n",
       " '150.27': 0.26242686510825858,\n",
       " '150.28': 0.2624147474225178,\n",
       " '150.29': 0.26241734872921452,\n",
       " '150.210': 0.26242807198409296,\n",
       " '150.220': 0.2624001385167275,\n",
       " '150.230': 0.26237192371681961,\n",
       " '150.240': 0.26244522919189806,\n",
       " '150.250': 0.26241732018823205,\n",
       " '150.270': 0.2624289200590032,\n",
       " '150.290': 0.26242792927918002,\n",
       " '150.31': 0.2624138952703241,\n",
       " '150.32': 0.26244058924358932,\n",
       " '150.33': 0.26242105090238171,\n",
       " '150.34': 0.26241422145298199,\n",
       " '150.35': 0.26240367352128241,\n",
       " '150.36': 0.26242529535421738,\n",
       " '150.37': 0.26241001369669531,\n",
       " '150.38': 0.26243048573576133,\n",
       " '150.39': 0.26239460972067613,\n",
       " '150.310': 0.26242803936582704,\n",
       " '150.320': 0.26242856533536285,\n",
       " '150.330': 0.2624354233257451,\n",
       " '150.340': 0.26241573412505786,\n",
       " '150.350': 0.2624351134522202,\n",
       " '150.370': 0.26242712197710161,\n",
       " '150.390': 0.26247176415111773,\n",
       " '150.41': 0.26244028752463089,\n",
       " '150.42': 0.26246550552136927,\n",
       " '150.43': 0.26240902291687185,\n",
       " '150.44': 0.2624342449908933,\n",
       " '150.45': 0.26237761560419992,\n",
       " '150.46': 0.26242991491610979,\n",
       " '150.47': 0.26244800174449023,\n",
       " '150.48': 0.26242155648550147,\n",
       " '150.49': 0.26243083230483522,\n",
       " '150.410': 0.26243527246626575,\n",
       " '150.420': 0.2624270812042695,\n",
       " '150.430': 0.2624209571248674,\n",
       " '150.440': 0.26243120741489173,\n",
       " '150.450': 0.26242230262833127,\n",
       " '150.470': 0.26241447016725877,\n",
       " '150.490': 0.26242383160954008,\n",
       " '150.51': 0.26241409505720203,\n",
       " '150.52': 0.26243613685030931,\n",
       " '150.53': 0.26244434849872161,\n",
       " '150.54': 0.26242792927918002,\n",
       " '150.55': 0.26242545844554638,\n",
       " '150.56': 0.26242604149704746,\n",
       " '150.57': 0.26242627390219125,\n",
       " '150.58': 0.26240654392867196,\n",
       " '150.59': 0.26242781511524971,\n",
       " '150.510': 0.26242801082484452,\n",
       " '150.520': 0.26242801897941098,\n",
       " '150.530': 0.26243568019458813,\n",
       " '150.540': 0.26243542740302822,\n",
       " '150.550': 0.26241896741065429,\n",
       " '150.570': 0.26241660258638472,\n",
       " '150.590': 0.26242810052507543,\n",
       " '150.61': 0.26242580093733714,\n",
       " '150.62': 0.26242793743374654,\n",
       " '150.63': 0.26239365563640188,\n",
       " '150.64': 0.26243532139366454,\n",
       " '150.65': 0.26242913207773105,\n",
       " '150.66': 0.26241787469875039,\n",
       " '150.67': 0.26243501559742277,\n",
       " '150.68': 0.26242931963275934,\n",
       " '150.69': 0.2624395821546332,\n",
       " '150.610': 0.2624202436003033,\n",
       " '150.620': 0.262448674496222,\n",
       " '150.630': 0.2624200193497262,\n",
       " '150.640': 0.26243601860909582,\n",
       " '150.650': 0.262422734820353,\n",
       " '150.670': 0.26242178889064505,\n",
       " '150.690': 0.26242834516206887,\n",
       " '150.71': 0.26243808171440691,\n",
       " '150.72': 0.26239619170656686,\n",
       " '150.73': 0.26241669228661568,\n",
       " '150.74': 0.2624550717536,\n",
       " '150.75': 0.26241353646940035,\n",
       " '150.76': 0.26244095619907959,\n",
       " '150.77': 0.26241426630309744,\n",
       " '150.78': 0.26247803501271549,\n",
       " ...}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262483490418\n",
      "130.770\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "par = \"\"\n",
    "for key in preds:\n",
    "    if preds[key] > max_score: \n",
    "        max_score = preds[key]\n",
    "        par = key\n",
    "print(max_score)\n",
    "print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 45s, sys: 9.84 s, total: 6min 55s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reset_rf_samples()\n",
    "clf = RandomForestClassifier(n_estimators=175, max_depth=10, max_leaf_nodes=50,n_jobs=-1)\n",
    "# Fit the whole dataset\n",
    "clf.fit(df.drop(['target', 'id'], axis=1), df.target)\n",
    "# Load in test dataset\n",
    "test_df = pd.read_csv(f'{PATH}test.csv', low_memory = False)\n",
    "# Predict probabilites for test data\n",
    "result = clf.predict_proba(test_df.drop('id', axis=1))\n",
    "predictions = [row[1] for row in result]\n",
    "id_list = test_df.id.tolist()\n",
    "writeTOfile(id_list, predictions, \"submission3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??set_rf_samples()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
